{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a198c560",
   "metadata": {},
   "source": [
    "1derin ogrenmede feature enginner e gerek yok\n",
    "2trensorflow kulaniyoruz.keras - API kulaniliyor\n",
    "3tensor- cok boyutlu matrix  flow akis google tarafindan gelistirildi.\n",
    "rakip -facebook pytoch\n",
    "4GPU(ekran katlari ile hesap yapmak daha hizli )\n",
    "5 derin ogrenme insan beynnin seklini koplayar,insan beyni nasil ogrenirse yapay sinir aglari oyle ogrenirler \n",
    "6 norunlar arasinda gidip gelme isleminin epoch denir\n",
    "7 her norundan digerine bir agirlik aktarilir (katsayi)aktarilir\n",
    "8 aktarma isleminde aktivasyon fonkisiyonun karar verir,softmax,sigmoid \n",
    "9 resimler cok buyuk oldugu icin parca-parca islenir buna batch-size denir\n",
    "10 resimler uzerinde calisiyorsaniz CNN kulanilir \n",
    "11resim,text (yazi),video uretme islemler LSTM ile yapilir (long-short time memeory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f586509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###deep learing ile makine ogrenmesi 1-callasfication 2-regresion 3 clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5f69e",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287ddae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: packaging in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yurt7/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e546a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 10:55:08.771583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d054fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04054137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c9a73e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9665e7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e11b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0915d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a8fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[[\"Outcome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8301f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]\n",
    "y=df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d848c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de59cb38",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 10:55:14.641643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")\n",
    "#adam=ogrenme hizi dusukse yukseltiyor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f75792",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 3.7492 - accuracy: 0.4284\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.6211\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.6120\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6146\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6367\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6354\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6458\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6576\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6562\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.6523\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6875\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6732\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6758\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6680\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6979\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6966\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6979\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6719\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6797\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6901\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6979\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6992\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6784\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7083\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.7096\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6966\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7174\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7005\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7070\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7070\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7188\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7122\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7096\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7122\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7318\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7266\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7044\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7201\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7214\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7344\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7201\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7253\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7331\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7305\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7279\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.6940\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7344\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7344\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7318\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7396\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7279\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7396\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7344\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7318\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7240\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7266\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7344\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7240\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7305\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7188\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7370\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7357\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7318\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7357\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7409\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7383\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7409\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7435\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7344\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7526\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7578\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7487\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7422\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7409\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7396\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7409\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.7448\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7487\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7435\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7435\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7422\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7253\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7552\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7461\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7409\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7383\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7370\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7578\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7435\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7474\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7461\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7461\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7409\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7448\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7474\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7526\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7448\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7539\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7370\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7422\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7461\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7539\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7422\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7396\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7513\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7422\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7513\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7370\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7539\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7487\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7513\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7461\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7513\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7604\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7370\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7643\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7435\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7513\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7513\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7435\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7435\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7565\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7500\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7630\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7474\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7552\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7565\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7448\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7383\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7630\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7565\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7487\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7565\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7565\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7513\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7461\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7500\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7487\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7539\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7604\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7578\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7539\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7604\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7526\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7591\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7422\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7539\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa946fee8e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=150,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35659c92",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ebb151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7461\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aceac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74609375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e05222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00fd672b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7834 - val_loss: 0.4441 - val_accuracy: 0.8117\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7785 - val_loss: 0.4651 - val_accuracy: 0.8052\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7818 - val_loss: 0.4871 - val_accuracy: 0.7597\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7997 - val_loss: 0.4552 - val_accuracy: 0.7792\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7818 - val_loss: 0.4549 - val_accuracy: 0.7922\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7899 - val_loss: 0.4678 - val_accuracy: 0.7987\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.7850 - val_loss: 0.4499 - val_accuracy: 0.7922\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.7769 - val_loss: 0.4503 - val_accuracy: 0.7922\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7736 - val_loss: 0.4641 - val_accuracy: 0.8052\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7720 - val_loss: 0.5056 - val_accuracy: 0.7727\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7590 - val_loss: 0.4842 - val_accuracy: 0.7857\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7704 - val_loss: 0.4535 - val_accuracy: 0.8052\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7866 - val_loss: 0.6043 - val_accuracy: 0.7013\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7932 - val_loss: 0.4507 - val_accuracy: 0.8117\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7850 - val_loss: 0.4925 - val_accuracy: 0.7338\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7850 - val_loss: 0.4940 - val_accuracy: 0.7727\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7964 - val_loss: 0.4841 - val_accuracy: 0.7792\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7866 - val_loss: 0.4755 - val_accuracy: 0.7987\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7532\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.7866 - val_loss: 0.4960 - val_accuracy: 0.7662\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7818 - val_loss: 0.4823 - val_accuracy: 0.7922\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7899 - val_loss: 0.4674 - val_accuracy: 0.7792\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7850 - val_loss: 0.4791 - val_accuracy: 0.7857\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7720 - val_loss: 0.4675 - val_accuracy: 0.7987\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7769 - val_loss: 0.4637 - val_accuracy: 0.7792\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7752 - val_loss: 0.4858 - val_accuracy: 0.7792\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.7818 - val_loss: 0.4963 - val_accuracy: 0.7857\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.7915 - val_loss: 0.4536 - val_accuracy: 0.8052\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.7948 - val_loss: 0.4659 - val_accuracy: 0.7857\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7883 - val_loss: 0.4992 - val_accuracy: 0.7987\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7769 - val_loss: 0.5058 - val_accuracy: 0.7727\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7915 - val_loss: 0.4792 - val_accuracy: 0.7857\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7671 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7704 - val_loss: 0.5264 - val_accuracy: 0.7597\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7883 - val_loss: 0.4990 - val_accuracy: 0.7597\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7866 - val_loss: 0.4988 - val_accuracy: 0.7532\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7834 - val_loss: 0.4913 - val_accuracy: 0.7727\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.7834 - val_loss: 0.5263 - val_accuracy: 0.7727\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7834 - val_loss: 0.5211 - val_accuracy: 0.7662\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7850 - val_loss: 0.4974 - val_accuracy: 0.7597\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.7899 - val_loss: 0.5205 - val_accuracy: 0.7597\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7850 - val_loss: 0.4798 - val_accuracy: 0.7857\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7769 - val_loss: 0.4935 - val_accuracy: 0.7792\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7834 - val_loss: 0.5356 - val_accuracy: 0.7403\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7769 - val_loss: 0.4912 - val_accuracy: 0.7662\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7899 - val_loss: 0.4796 - val_accuracy: 0.7727\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7785 - val_loss: 0.4981 - val_accuracy: 0.7792\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7834 - val_loss: 0.4863 - val_accuracy: 0.7597\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7883 - val_loss: 0.4663 - val_accuracy: 0.7857\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7818 - val_loss: 0.5105 - val_accuracy: 0.7727\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.7883 - val_loss: 0.5185 - val_accuracy: 0.7727\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.7964 - val_loss: 0.5171 - val_accuracy: 0.7662\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7704 - val_loss: 0.5785 - val_accuracy: 0.7662\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7785 - val_loss: 0.4927 - val_accuracy: 0.7792\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7818 - val_loss: 0.4893 - val_accuracy: 0.7727\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.7720 - val_loss: 0.5184 - val_accuracy: 0.7922\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7834 - val_loss: 0.4960 - val_accuracy: 0.7597\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7769 - val_loss: 0.5071 - val_accuracy: 0.7597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7915 - val_loss: 0.5217 - val_accuracy: 0.7468\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.7801 - val_loss: 0.4964 - val_accuracy: 0.7857\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.7964 - val_loss: 0.5231 - val_accuracy: 0.7597\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7785 - val_loss: 0.5116 - val_accuracy: 0.7792\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.7948 - val_loss: 0.5343 - val_accuracy: 0.7662\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7662\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7720 - val_loss: 0.5426 - val_accuracy: 0.7273\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7866 - val_loss: 0.5004 - val_accuracy: 0.7597\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.7932 - val_loss: 0.5049 - val_accuracy: 0.7468\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.7915 - val_loss: 0.5452 - val_accuracy: 0.7792\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.7866 - val_loss: 0.5487 - val_accuracy: 0.7662\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7752 - val_loss: 0.5127 - val_accuracy: 0.7597\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7785 - val_loss: 0.5405 - val_accuracy: 0.7597\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7883 - val_loss: 0.5258 - val_accuracy: 0.7532\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.7818 - val_loss: 0.5021 - val_accuracy: 0.7727\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.7932 - val_loss: 0.5220 - val_accuracy: 0.7597\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7655 - val_loss: 0.5592 - val_accuracy: 0.7403\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7980 - val_loss: 0.5023 - val_accuracy: 0.7532\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7818 - val_loss: 0.5379 - val_accuracy: 0.7857\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7866 - val_loss: 0.5211 - val_accuracy: 0.7662\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.7932 - val_loss: 0.5753 - val_accuracy: 0.7532\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.7948 - val_loss: 0.5074 - val_accuracy: 0.7792\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8046 - val_loss: 0.5367 - val_accuracy: 0.7857\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.7948 - val_loss: 0.5202 - val_accuracy: 0.7922\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.7997 - val_loss: 0.4899 - val_accuracy: 0.7727\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8046 - val_loss: 0.5045 - val_accuracy: 0.7727\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.7915 - val_loss: 0.5101 - val_accuracy: 0.7662\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.7899 - val_loss: 0.5724 - val_accuracy: 0.7403\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.7932 - val_loss: 0.5333 - val_accuracy: 0.7597\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7850 - val_loss: 0.5068 - val_accuracy: 0.7792\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.7932 - val_loss: 0.5002 - val_accuracy: 0.7922\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.7899 - val_loss: 0.5811 - val_accuracy: 0.7662\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.7850 - val_loss: 0.4957 - val_accuracy: 0.7857\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.7801 - val_loss: 0.5244 - val_accuracy: 0.7727\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.7834 - val_loss: 0.5137 - val_accuracy: 0.7857\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.7801 - val_loss: 0.5617 - val_accuracy: 0.7403\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.7915 - val_loss: 0.5605 - val_accuracy: 0.7662\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.7704 - val_loss: 0.5405 - val_accuracy: 0.7662\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.7834 - val_loss: 0.5886 - val_accuracy: 0.7532\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.7915 - val_loss: 0.5107 - val_accuracy: 0.7792\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.7850 - val_loss: 0.5337 - val_accuracy: 0.7792\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7727\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.7899 - val_loss: 0.4905 - val_accuracy: 0.7792\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.7850 - val_loss: 0.5076 - val_accuracy: 0.7857\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.7980 - val_loss: 0.4938 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8029 - val_loss: 0.5527 - val_accuracy: 0.7532\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8013 - val_loss: 0.5908 - val_accuracy: 0.7338\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.7899 - val_loss: 0.5341 - val_accuracy: 0.7727\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8013 - val_loss: 0.5428 - val_accuracy: 0.7597\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7850 - val_loss: 0.5643 - val_accuracy: 0.7532\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.7932 - val_loss: 0.5599 - val_accuracy: 0.7532\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.7866 - val_loss: 0.5551 - val_accuracy: 0.7597\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.7866 - val_loss: 0.5540 - val_accuracy: 0.7468\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.7932 - val_loss: 0.5943 - val_accuracy: 0.7597\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.7964 - val_loss: 0.5295 - val_accuracy: 0.7792\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.7932 - val_loss: 0.5078 - val_accuracy: 0.7662\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.7932 - val_loss: 0.5215 - val_accuracy: 0.7403\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7866 - val_loss: 0.5147 - val_accuracy: 0.7662\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.7948 - val_loss: 0.5469 - val_accuracy: 0.7597\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.7948 - val_loss: 0.5005 - val_accuracy: 0.7792\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8013 - val_loss: 0.5511 - val_accuracy: 0.7857\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.7801 - val_loss: 0.5205 - val_accuracy: 0.7792\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.7834 - val_loss: 0.5126 - val_accuracy: 0.7597\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7769 - val_loss: 0.5204 - val_accuracy: 0.7468\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7883 - val_loss: 0.5345 - val_accuracy: 0.7662\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.7932 - val_loss: 0.6040 - val_accuracy: 0.7468\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7915 - val_loss: 0.5560 - val_accuracy: 0.7662\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7915 - val_loss: 0.5414 - val_accuracy: 0.7597\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.7997 - val_loss: 0.5264 - val_accuracy: 0.7662\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8013 - val_loss: 0.5749 - val_accuracy: 0.7727\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.7850 - val_loss: 0.5596 - val_accuracy: 0.7468\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.7932 - val_loss: 0.5456 - val_accuracy: 0.7597\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.7964 - val_loss: 0.5326 - val_accuracy: 0.7662\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.7850 - val_loss: 0.5418 - val_accuracy: 0.7532\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.7866 - val_loss: 0.5434 - val_accuracy: 0.7532\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.7850 - val_loss: 0.5302 - val_accuracy: 0.7727\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.7980 - val_loss: 0.5274 - val_accuracy: 0.7857\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.7932 - val_loss: 0.5660 - val_accuracy: 0.7597\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.7997 - val_loss: 0.5382 - val_accuracy: 0.7857\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.7964 - val_loss: 0.5408 - val_accuracy: 0.7727\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.7883 - val_loss: 0.5327 - val_accuracy: 0.7857\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.7899 - val_loss: 0.5749 - val_accuracy: 0.7727\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8078 - val_loss: 0.5860 - val_accuracy: 0.7532\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.7964 - val_loss: 0.5394 - val_accuracy: 0.7727\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.7899 - val_loss: 0.5517 - val_accuracy: 0.7532\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.7948 - val_loss: 0.5703 - val_accuracy: 0.7403\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.7915 - val_loss: 0.5562 - val_accuracy: 0.7727\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.7785 - val_loss: 0.5819 - val_accuracy: 0.7792\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7932 - val_loss: 0.5903 - val_accuracy: 0.7403\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7834 - val_loss: 0.5616 - val_accuracy: 0.7727\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7704 - val_loss: 0.5298 - val_accuracy: 0.7727\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7883 - val_loss: 0.5486 - val_accuracy: 0.7468\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=150,validation_split=0.20,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81dcec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d76ac363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa930a458e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e5b069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d138b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c48edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"kc_house.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "694485ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b422f258",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        221900.0\n",
       "1        538000.0\n",
       "2        180000.0\n",
       "3        604000.0\n",
       "4        510000.0\n",
       "           ...   \n",
       "21608    360000.0\n",
       "21609    400000.0\n",
       "21610    402101.0\n",
       "21611    400000.0\n",
       "21612    325000.0\n",
       "Name: price, Length: 19034, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84b70be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"price\",axis=1)\n",
    "y=df[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4485ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "887ca5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f040c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ae98242",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c16ddf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7108071936.0000 - val_loss: 7953509376.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7046902784.0000 - val_loss: 7910292992.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7357752832.0000 - val_loss: 8134862848.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7176019968.0000 - val_loss: 7975551488.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179525632.0000 - val_loss: 8064217088.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7263645184.0000 - val_loss: 7907103744.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7123283456.0000 - val_loss: 7958025216.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7250245632.0000 - val_loss: 8641487872.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077181952.0000 - val_loss: 7943165952.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179852800.0000 - val_loss: 7921755136.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7300556288.0000 - val_loss: 7931931648.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7147970560.0000 - val_loss: 8697591808.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7155139584.0000 - val_loss: 8065172480.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7115164672.0000 - val_loss: 8055597056.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7394741760.0000 - val_loss: 7937435648.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056936960.0000 - val_loss: 8175643136.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149607424.0000 - val_loss: 8860374016.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7192414720.0000 - val_loss: 7959525888.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047712256.0000 - val_loss: 8145519104.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7258488320.0000 - val_loss: 8370641408.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7070536192.0000 - val_loss: 8757451776.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7217886720.0000 - val_loss: 8733821952.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7130940416.0000 - val_loss: 8081697280.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7123334144.0000 - val_loss: 8100009472.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7063790080.0000 - val_loss: 7942213632.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7222833152.0000 - val_loss: 8188732416.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077246976.0000 - val_loss: 7903329280.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7217690112.0000 - val_loss: 7909446144.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7286211584.0000 - val_loss: 7913026560.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7190824960.0000 - val_loss: 8000330752.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7190633472.0000 - val_loss: 8078597120.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7168846336.0000 - val_loss: 8260564480.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7467594752.0000 - val_loss: 8102543872.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7046423552.0000 - val_loss: 7975176704.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7270263296.0000 - val_loss: 7912816128.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7124587520.0000 - val_loss: 8016514560.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7084187648.0000 - val_loss: 8034994688.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7365872128.0000 - val_loss: 8040523264.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7233210368.0000 - val_loss: 8005892608.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7249520640.0000 - val_loss: 8092595200.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7142740992.0000 - val_loss: 7931228672.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7082651136.0000 - val_loss: 7959983104.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7187320832.0000 - val_loss: 8314584576.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7167502336.0000 - val_loss: 7970145792.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7094517760.0000 - val_loss: 8086086144.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7247959040.0000 - val_loss: 8611187712.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7249380352.0000 - val_loss: 8064322560.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7222063616.0000 - val_loss: 8333500928.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7223881728.0000 - val_loss: 8089037312.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151390208.0000 - val_loss: 7885301760.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7208423424.0000 - val_loss: 7992316928.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024590848.0000 - val_loss: 8062735360.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7080069120.0000 - val_loss: 8156842496.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151014912.0000 - val_loss: 7973073408.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7164942848.0000 - val_loss: 8127857152.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087592448.0000 - val_loss: 8215506432.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7176167936.0000 - val_loss: 8052025856.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7308418560.0000 - val_loss: 8655460352.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7091983872.0000 - val_loss: 7877142016.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7292260352.0000 - val_loss: 8105475072.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7377632768.0000 - val_loss: 8239556608.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7192126464.0000 - val_loss: 8586870272.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179119104.0000 - val_loss: 8443531264.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7190609920.0000 - val_loss: 8151312896.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7134530048.0000 - val_loss: 8233271296.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7182177792.0000 - val_loss: 8419387392.0000\n",
      "Epoch 67/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7093520384.0000 - val_loss: 8045565952.0000\n",
      "Epoch 68/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7108283392.0000 - val_loss: 8273025536.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7315262464.0000 - val_loss: 8624307200.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7385551360.0000 - val_loss: 7999280128.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7048192512.0000 - val_loss: 8474061312.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7207310336.0000 - val_loss: 7861061120.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136724992.0000 - val_loss: 7941527552.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7064123904.0000 - val_loss: 7871586304.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7060764160.0000 - val_loss: 7910461952.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7123066368.0000 - val_loss: 8125308416.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7098246656.0000 - val_loss: 7880944640.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7571114496.0000 - val_loss: 7883956224.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7079766016.0000 - val_loss: 8079618048.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7144020992.0000 - val_loss: 7996484608.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7120124416.0000 - val_loss: 7996578816.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7200234496.0000 - val_loss: 8363865088.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7225195520.0000 - val_loss: 8207263744.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7390200832.0000 - val_loss: 8040374784.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7263861248.0000 - val_loss: 8359074816.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7180718080.0000 - val_loss: 8904823808.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7140074496.0000 - val_loss: 8619550720.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7163299840.0000 - val_loss: 8048261632.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7196393984.0000 - val_loss: 8017445888.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7312750592.0000 - val_loss: 7935865856.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7254522368.0000 - val_loss: 8155335680.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7112564736.0000 - val_loss: 7880822784.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7132714496.0000 - val_loss: 8307377152.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7188071424.0000 - val_loss: 7875933696.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7138207232.0000 - val_loss: 7925747712.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7359228416.0000 - val_loss: 8126822400.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7197845504.0000 - val_loss: 8031701504.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7169939456.0000 - val_loss: 8098767872.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7140702208.0000 - val_loss: 7946298368.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7103812096.0000 - val_loss: 7964983296.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7051230720.0000 - val_loss: 8121262592.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7267178496.0000 - val_loss: 7891705856.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179206144.0000 - val_loss: 7937481728.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7209079808.0000 - val_loss: 7969913344.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7303166976.0000 - val_loss: 7940731904.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7292387840.0000 - val_loss: 7920937984.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7203334656.0000 - val_loss: 7968035328.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7355322368.0000 - val_loss: 7933822464.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7238354432.0000 - val_loss: 7995258368.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7302269952.0000 - val_loss: 8205592576.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7040454144.0000 - val_loss: 7939270144.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7180726272.0000 - val_loss: 7847423488.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7119931904.0000 - val_loss: 8085559296.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7131962880.0000 - val_loss: 8023004160.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7245076992.0000 - val_loss: 7973634048.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7174583296.0000 - val_loss: 8058650112.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7237895168.0000 - val_loss: 8800069632.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7170591744.0000 - val_loss: 8830594048.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7027288064.0000 - val_loss: 8039477760.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7173746176.0000 - val_loss: 8524574208.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7213470208.0000 - val_loss: 7909939712.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244040704.0000 - val_loss: 7890329600.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7065183232.0000 - val_loss: 7870316032.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7198599680.0000 - val_loss: 7881062912.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038420480.0000 - val_loss: 8139817984.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965849088.0000 - val_loss: 7874640384.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7280619008.0000 - val_loss: 7888804864.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7247629824.0000 - val_loss: 8315078656.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7210136064.0000 - val_loss: 8216356352.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7180502016.0000 - val_loss: 7878824448.0000\n",
      "Epoch 131/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7239739904.0000 - val_loss: 7887350784.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7223969280.0000 - val_loss: 8615517184.0000\n",
      "Epoch 133/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7334632448.0000 - val_loss: 8174176256.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7089741312.0000 - val_loss: 8344442880.0000\n",
      "Epoch 135/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7169286656.0000 - val_loss: 8510563328.0000\n",
      "Epoch 136/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7216407552.0000 - val_loss: 8192995328.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7039752192.0000 - val_loss: 7861344256.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7133108224.0000 - val_loss: 7863454720.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7138019328.0000 - val_loss: 8550128128.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7206295040.0000 - val_loss: 8520027136.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7121030144.0000 - val_loss: 7890762240.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7169584128.0000 - val_loss: 8035805696.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7187411456.0000 - val_loss: 7889723904.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7225127936.0000 - val_loss: 8028657664.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7046239232.0000 - val_loss: 8197883392.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7051851264.0000 - val_loss: 7939622400.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7052276224.0000 - val_loss: 7846758400.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7246829568.0000 - val_loss: 8094576128.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7053480448.0000 - val_loss: 8843141120.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7162479616.0000 - val_loss: 7938349056.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075134464.0000 - val_loss: 7885393408.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7423646720.0000 - val_loss: 9420953600.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7156930560.0000 - val_loss: 7975580672.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7119579136.0000 - val_loss: 8065199104.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7142877184.0000 - val_loss: 7959790592.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7481694208.0000 - val_loss: 8063501312.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7263392256.0000 - val_loss: 9127156736.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7339661312.0000 - val_loss: 8558239744.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7173099520.0000 - val_loss: 7922111488.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047044608.0000 - val_loss: 8078388736.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200982528.0000 - val_loss: 8090821632.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7122131968.0000 - val_loss: 8225808384.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7350599680.0000 - val_loss: 8215047168.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015985152.0000 - val_loss: 7879133696.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200278016.0000 - val_loss: 8456614912.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7079445504.0000 - val_loss: 8156382208.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7280227328.0000 - val_loss: 8143949312.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7092716544.0000 - val_loss: 7959233024.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7215491072.0000 - val_loss: 8191667200.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7106033152.0000 - val_loss: 7893786624.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7152872448.0000 - val_loss: 7873680896.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7034760192.0000 - val_loss: 8081136128.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7230755328.0000 - val_loss: 7866731520.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7321491968.0000 - val_loss: 7987994112.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7261310464.0000 - val_loss: 8548364288.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7153972736.0000 - val_loss: 8119163392.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7069848064.0000 - val_loss: 7935729152.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7013266944.0000 - val_loss: 7870541824.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7040755712.0000 - val_loss: 8100451840.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016226304.0000 - val_loss: 7952689152.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7124734976.0000 - val_loss: 8344283648.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7081658880.0000 - val_loss: 7882263040.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7074924032.0000 - val_loss: 8056421888.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7062350336.0000 - val_loss: 7905264128.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7230539264.0000 - val_loss: 7949491200.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7078416384.0000 - val_loss: 7881920000.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7113401344.0000 - val_loss: 7924292608.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7078068736.0000 - val_loss: 7898007040.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7126056960.0000 - val_loss: 7925943808.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7150906368.0000 - val_loss: 7970771456.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7286033920.0000 - val_loss: 7990114816.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7156389888.0000 - val_loss: 7904882176.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7072669696.0000 - val_loss: 8059777536.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145329664.0000 - val_loss: 7995715584.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7155845632.0000 - val_loss: 7889585152.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7071918592.0000 - val_loss: 8053463040.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7159251456.0000 - val_loss: 7866778112.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029950464.0000 - val_loss: 7956064768.0000\n",
      "Epoch 199/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7329231360.0000 - val_loss: 7903290880.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145977344.0000 - val_loss: 8181089792.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7090294784.0000 - val_loss: 7904039936.0000\n",
      "Epoch 202/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7162906112.0000 - val_loss: 8355879936.0000\n",
      "Epoch 203/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7113906688.0000 - val_loss: 7892850688.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7034627584.0000 - val_loss: 8265235968.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7103608320.0000 - val_loss: 7921471488.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7091028480.0000 - val_loss: 8435049984.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7099783680.0000 - val_loss: 7923902464.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7039811584.0000 - val_loss: 7859406848.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7037682688.0000 - val_loss: 8598808576.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7120697856.0000 - val_loss: 7977754624.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7259662336.0000 - val_loss: 8038458880.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7170524160.0000 - val_loss: 8278088704.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7039596544.0000 - val_loss: 8129612288.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7144659456.0000 - val_loss: 8707733504.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7210258432.0000 - val_loss: 7853884928.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6989346304.0000 - val_loss: 7938247680.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7107345408.0000 - val_loss: 7872379904.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7107581440.0000 - val_loss: 8068718592.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7109161472.0000 - val_loss: 8177425920.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145429504.0000 - val_loss: 7963386368.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7113357312.0000 - val_loss: 8026767360.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7073360384.0000 - val_loss: 7983715328.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7302474240.0000 - val_loss: 7937615872.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7143727104.0000 - val_loss: 7870047744.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7222093824.0000 - val_loss: 8092450304.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7173483008.0000 - val_loss: 8220212736.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7070242304.0000 - val_loss: 8320437760.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7101103104.0000 - val_loss: 7977058816.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7162143232.0000 - val_loss: 8042547712.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7098659840.0000 - val_loss: 8275658240.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7208683008.0000 - val_loss: 7997759488.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077732352.0000 - val_loss: 7896658432.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7325625856.0000 - val_loss: 8078032896.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961358848.0000 - val_loss: 7880364032.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7307488256.0000 - val_loss: 7871424512.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6984071168.0000 - val_loss: 8112785408.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7144629760.0000 - val_loss: 7902476288.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7018993152.0000 - val_loss: 7896150016.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7097077248.0000 - val_loss: 8118754816.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7043196928.0000 - val_loss: 7917646848.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7103237120.0000 - val_loss: 8430871040.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7128129536.0000 - val_loss: 7843004416.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7088540160.0000 - val_loss: 7915044352.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991776256.0000 - val_loss: 7972883456.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050289152.0000 - val_loss: 7890200064.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7036662784.0000 - val_loss: 7857944064.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7063601152.0000 - val_loss: 7965856768.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6988614144.0000 - val_loss: 8022039040.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7286802432.0000 - val_loss: 8273504768.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7126191616.0000 - val_loss: 7903384576.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7053659136.0000 - val_loss: 8404173312.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7076371968.0000 - val_loss: 7982050816.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7107573248.0000 - val_loss: 8166925312.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7192614400.0000 - val_loss: 8160144384.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015629312.0000 - val_loss: 8021040640.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7160630272.0000 - val_loss: 8017694208.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7128104960.0000 - val_loss: 8060072448.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7166296064.0000 - val_loss: 8054294528.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7039391744.0000 - val_loss: 8010458624.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7070626816.0000 - val_loss: 7932948480.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052029440.0000 - val_loss: 7986485248.0000\n",
      "Epoch 262/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7158157824.0000 - val_loss: 7862314496.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999503872.0000 - val_loss: 7922820096.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7153143296.0000 - val_loss: 8466369024.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7004961792.0000 - val_loss: 7922151936.0000\n",
      "Epoch 266/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7039998464.0000 - val_loss: 7993632768.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7260262912.0000 - val_loss: 8003626496.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7105428992.0000 - val_loss: 7943408640.0000\n",
      "Epoch 269/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7187582464.0000 - val_loss: 8041201152.0000\n",
      "Epoch 270/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6975109632.0000 - val_loss: 7953544192.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7137477632.0000 - val_loss: 8374065152.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7177492992.0000 - val_loss: 8004556288.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6988956672.0000 - val_loss: 8084076032.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149465088.0000 - val_loss: 8048598528.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050854400.0000 - val_loss: 7853058048.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7157779968.0000 - val_loss: 9959383040.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7170019840.0000 - val_loss: 9039115264.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7128259584.0000 - val_loss: 8306041856.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024719360.0000 - val_loss: 7884849152.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7072178176.0000 - val_loss: 8158789632.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7155491328.0000 - val_loss: 8585262592.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7165239808.0000 - val_loss: 7991813632.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035279360.0000 - val_loss: 8052442112.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056841216.0000 - val_loss: 7953083904.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7023177216.0000 - val_loss: 8216472064.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149949440.0000 - val_loss: 9137108992.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7352613376.0000 - val_loss: 8022534656.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7205220864.0000 - val_loss: 8775140352.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7135387648.0000 - val_loss: 8053998592.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7114192384.0000 - val_loss: 8028536320.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7158846464.0000 - val_loss: 8496213504.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7017291776.0000 - val_loss: 8065078272.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7257973760.0000 - val_loss: 8459578368.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052668928.0000 - val_loss: 8551136768.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7204544512.0000 - val_loss: 7859588096.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029222400.0000 - val_loss: 8102967808.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7043799040.0000 - val_loss: 7855306752.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7139656704.0000 - val_loss: 7911695872.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029469184.0000 - val_loss: 8104206336.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7204412416.0000 - val_loss: 7907709440.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7065907200.0000 - val_loss: 7868919808.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6940858880.0000 - val_loss: 7960118784.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7182083072.0000 - val_loss: 8023390208.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7011662848.0000 - val_loss: 8940965888.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7175835136.0000 - val_loss: 7934751744.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035072512.0000 - val_loss: 7910497792.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6986708480.0000 - val_loss: 7975583744.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7196717568.0000 - val_loss: 7844508160.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7078506496.0000 - val_loss: 7901073920.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149311488.0000 - val_loss: 8004147712.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015203328.0000 - val_loss: 7944315904.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7115223040.0000 - val_loss: 7967022080.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7061391360.0000 - val_loss: 7955231744.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151305216.0000 - val_loss: 7884377088.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7144783360.0000 - val_loss: 8192989696.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6972881920.0000 - val_loss: 8179035136.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6944635392.0000 - val_loss: 7836574720.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7140616704.0000 - val_loss: 7993633280.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7017680384.0000 - val_loss: 7937650176.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7119987200.0000 - val_loss: 7909822976.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7274386944.0000 - val_loss: 8013606912.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7082596864.0000 - val_loss: 7945341952.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7033048064.0000 - val_loss: 7952193024.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7293396480.0000 - val_loss: 8001708544.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977178112.0000 - val_loss: 7881941504.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087373824.0000 - val_loss: 7883092992.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087801344.0000 - val_loss: 8399846400.0000\n",
      "Epoch 328/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7083619328.0000 - val_loss: 8496248832.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7425160192.0000 - val_loss: 8267040768.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7037089280.0000 - val_loss: 8210409984.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6995545088.0000 - val_loss: 8047870976.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6982042624.0000 - val_loss: 8133410816.0000\n",
      "Epoch 333/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7167970816.0000 - val_loss: 7889325568.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7175288832.0000 - val_loss: 7866273280.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7107947008.0000 - val_loss: 7911424512.0000\n",
      "Epoch 336/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7012984320.0000 - val_loss: 8096658432.0000\n",
      "Epoch 337/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7144765440.0000 - val_loss: 7932559360.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7078445056.0000 - val_loss: 7967854592.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7122427904.0000 - val_loss: 7866579456.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7167991808.0000 - val_loss: 9134902272.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7239535104.0000 - val_loss: 8694981632.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6956091392.0000 - val_loss: 8011849216.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7057307648.0000 - val_loss: 8369791488.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075321344.0000 - val_loss: 7812490240.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7032119296.0000 - val_loss: 7826199040.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6984112640.0000 - val_loss: 8112069632.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015813632.0000 - val_loss: 7935737344.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7069726720.0000 - val_loss: 7951128576.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047523840.0000 - val_loss: 8020786688.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7023404544.0000 - val_loss: 7876763136.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015174656.0000 - val_loss: 8079603712.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7040936448.0000 - val_loss: 8434721792.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7153313280.0000 - val_loss: 8382189056.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7245309952.0000 - val_loss: 7950661120.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7453227008.0000 - val_loss: 8308357632.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7230212608.0000 - val_loss: 8361285632.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200950272.0000 - val_loss: 9001090048.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7276441600.0000 - val_loss: 8323814912.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7008290816.0000 - val_loss: 7914268160.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7280357376.0000 - val_loss: 8327299072.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7064694784.0000 - val_loss: 8550038528.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020866048.0000 - val_loss: 8043437056.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7036505600.0000 - val_loss: 7845778944.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7018042880.0000 - val_loss: 7830497280.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7066345472.0000 - val_loss: 7945293824.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183736320.0000 - val_loss: 7962121728.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964912128.0000 - val_loss: 7928520704.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7123506176.0000 - val_loss: 8077399040.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056312320.0000 - val_loss: 7881578496.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7532699136.0000 - val_loss: 8169476096.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7031815680.0000 - val_loss: 7897404928.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7005192192.0000 - val_loss: 8626064384.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021359616.0000 - val_loss: 7876764160.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086722560.0000 - val_loss: 7986371072.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7041171968.0000 - val_loss: 8628441088.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7012306432.0000 - val_loss: 7934158848.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001586176.0000 - val_loss: 7823355904.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075360256.0000 - val_loss: 7882046464.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6985220608.0000 - val_loss: 7976948736.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024932864.0000 - val_loss: 7990050816.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981822976.0000 - val_loss: 8598310912.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7542180352.0000 - val_loss: 8126384640.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7070794752.0000 - val_loss: 7833929216.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7206371840.0000 - val_loss: 8054848512.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7153517568.0000 - val_loss: 7879005184.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7227796480.0000 - val_loss: 8082775040.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7014185472.0000 - val_loss: 8529531392.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7068059136.0000 - val_loss: 8297631232.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999389184.0000 - val_loss: 7984435712.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052284416.0000 - val_loss: 7954515968.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6976504320.0000 - val_loss: 7970737664.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966030848.0000 - val_loss: 8005556736.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7142689792.0000 - val_loss: 8156642304.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7102506496.0000 - val_loss: 8083938304.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7066010624.0000 - val_loss: 8120764416.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7013578752.0000 - val_loss: 7850471424.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953000960.0000 - val_loss: 7929605120.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7188353536.0000 - val_loss: 8066519552.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7095267840.0000 - val_loss: 8259643904.0000\n",
      "Epoch 400/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7061651456.0000 - val_loss: 9658434560.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6989947904.0000 - val_loss: 7908847104.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7083769856.0000 - val_loss: 8367470592.0000\n",
      "Epoch 403/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7061852672.0000 - val_loss: 8049915904.0000\n",
      "Epoch 404/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6951995392.0000 - val_loss: 7855386624.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7099133952.0000 - val_loss: 7927101440.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7044844032.0000 - val_loss: 7989070336.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7051675648.0000 - val_loss: 7871303168.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020993536.0000 - val_loss: 8168145920.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7116549632.0000 - val_loss: 7848483840.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7094217216.0000 - val_loss: 7929731584.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7015347200.0000 - val_loss: 8551947264.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7321552896.0000 - val_loss: 7907450368.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7006814720.0000 - val_loss: 8021540352.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6968240640.0000 - val_loss: 8033175552.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7007888896.0000 - val_loss: 8040031232.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077219840.0000 - val_loss: 8090154496.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7042801664.0000 - val_loss: 7992842240.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7146525696.0000 - val_loss: 7942969856.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7134542336.0000 - val_loss: 7953576960.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6949561856.0000 - val_loss: 7955470336.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6972954624.0000 - val_loss: 7820923904.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6930446848.0000 - val_loss: 7935925248.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6975702528.0000 - val_loss: 8025125376.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7096206848.0000 - val_loss: 8577182208.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7033269248.0000 - val_loss: 7912280576.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7102126080.0000 - val_loss: 7839571968.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086894080.0000 - val_loss: 8237030912.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016856576.0000 - val_loss: 8261738496.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7210645504.0000 - val_loss: 7814123520.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6995250688.0000 - val_loss: 8163201024.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7125849600.0000 - val_loss: 7911334400.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7061766656.0000 - val_loss: 8445345792.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6997466112.0000 - val_loss: 8513872384.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7005991424.0000 - val_loss: 8155423232.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7163680256.0000 - val_loss: 7818652672.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7080994304.0000 - val_loss: 7869938688.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100809728.0000 - val_loss: 8233695232.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6921231360.0000 - val_loss: 7842781184.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7025820160.0000 - val_loss: 8239040000.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6963292160.0000 - val_loss: 7835604992.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050854400.0000 - val_loss: 8108554752.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7215944192.0000 - val_loss: 7901842944.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6985714176.0000 - val_loss: 8275652096.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7004750336.0000 - val_loss: 8579651072.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999141376.0000 - val_loss: 8217717248.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7054045184.0000 - val_loss: 7953762816.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7127905792.0000 - val_loss: 7880240640.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7063553536.0000 - val_loss: 7890014208.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7237278720.0000 - val_loss: 8041041920.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7407834112.0000 - val_loss: 8424045056.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7415157760.0000 - val_loss: 7895626752.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964338688.0000 - val_loss: 7894443520.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7277705728.0000 - val_loss: 7907510272.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999400960.0000 - val_loss: 7840264704.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7132521984.0000 - val_loss: 8037174272.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6988947456.0000 - val_loss: 8253324288.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7085357056.0000 - val_loss: 7976272384.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897014272.0000 - val_loss: 7961835008.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6969503744.0000 - val_loss: 7923143168.0000\n",
      "Epoch 460/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6929470464.0000 - val_loss: 8219825664.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999029760.0000 - val_loss: 8256917504.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7262831104.0000 - val_loss: 8124097024.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993545216.0000 - val_loss: 7891567616.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7005177344.0000 - val_loss: 8312052736.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7090992128.0000 - val_loss: 8028463104.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6975574528.0000 - val_loss: 8088726528.0000\n",
      "Epoch 467/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6990243840.0000 - val_loss: 7926688256.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7036689408.0000 - val_loss: 8166829568.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7084284416.0000 - val_loss: 8003360768.0000\n",
      "Epoch 470/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7175151616.0000 - val_loss: 8138493952.0000\n",
      "Epoch 471/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7019042304.0000 - val_loss: 7876300800.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927883776.0000 - val_loss: 7814886912.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075626496.0000 - val_loss: 7977041408.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029900800.0000 - val_loss: 7928093184.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7067200000.0000 - val_loss: 8116525568.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7009154048.0000 - val_loss: 10088642560.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6985348608.0000 - val_loss: 7886639616.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955352576.0000 - val_loss: 8230373888.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7013171712.0000 - val_loss: 7983310336.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7518265856.0000 - val_loss: 7965793280.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965878784.0000 - val_loss: 8077818880.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922413568.0000 - val_loss: 7884534784.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7127907840.0000 - val_loss: 7861215232.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7191574528.0000 - val_loss: 7929418240.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024720896.0000 - val_loss: 7848107008.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981349888.0000 - val_loss: 7818526720.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938333696.0000 - val_loss: 7824897024.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7042743296.0000 - val_loss: 7955798016.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7011705856.0000 - val_loss: 7994392064.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7301868544.0000 - val_loss: 8051676672.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7275168256.0000 - val_loss: 8752277504.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7048960000.0000 - val_loss: 7852125696.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6960941056.0000 - val_loss: 7898812416.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6996975104.0000 - val_loss: 7898875392.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7003338240.0000 - val_loss: 8088878080.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7189174272.0000 - val_loss: 8304531456.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7033792000.0000 - val_loss: 7861786112.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024807424.0000 - val_loss: 7818670080.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7002497024.0000 - val_loss: 7937633792.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924143104.0000 - val_loss: 7908665344.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6910871552.0000 - val_loss: 8068263424.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6898148352.0000 - val_loss: 7990870528.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7105233408.0000 - val_loss: 8142705664.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955261440.0000 - val_loss: 8002891776.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6956699136.0000 - val_loss: 7928175616.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7242283008.0000 - val_loss: 8141223936.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6972063232.0000 - val_loss: 8457632256.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7097101824.0000 - val_loss: 7942806016.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7298212864.0000 - val_loss: 7868861440.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6923533824.0000 - val_loss: 8104931328.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7057470464.0000 - val_loss: 8390597632.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7026810880.0000 - val_loss: 7914295808.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7111291904.0000 - val_loss: 8868688896.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7224768000.0000 - val_loss: 8232249856.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993605632.0000 - val_loss: 8056870400.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6969277952.0000 - val_loss: 8062864384.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6958313472.0000 - val_loss: 7833347584.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7028533760.0000 - val_loss: 7908132864.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6988974592.0000 - val_loss: 8194267648.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993932800.0000 - val_loss: 7843668992.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6946947072.0000 - val_loss: 8601479168.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7289365504.0000 - val_loss: 8099826176.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6942650880.0000 - val_loss: 8056835584.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6998484480.0000 - val_loss: 8585238016.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200493568.0000 - val_loss: 8913007616.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7144258048.0000 - val_loss: 7904954880.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7085051392.0000 - val_loss: 8047637504.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7045268992.0000 - val_loss: 8083491328.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7154984960.0000 - val_loss: 7934867968.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7240244224.0000 - val_loss: 9308369920.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7308277248.0000 - val_loss: 7972706816.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7266304512.0000 - val_loss: 8178440704.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7155204096.0000 - val_loss: 8143693312.0000\n",
      "Epoch 534/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100508672.0000 - val_loss: 7870378496.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7041785856.0000 - val_loss: 7831222784.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6937472000.0000 - val_loss: 8210183168.0000\n",
      "Epoch 537/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077712896.0000 - val_loss: 7917912576.0000\n",
      "Epoch 538/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7052798976.0000 - val_loss: 7982530560.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7165194752.0000 - val_loss: 8331795968.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6907608064.0000 - val_loss: 7937244672.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6866979328.0000 - val_loss: 7859776000.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6995911168.0000 - val_loss: 8015928832.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6979984896.0000 - val_loss: 7878774272.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7008713216.0000 - val_loss: 7835918336.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7370296320.0000 - val_loss: 9624663040.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7208669696.0000 - val_loss: 7860314112.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885833728.0000 - val_loss: 7939694080.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6957136384.0000 - val_loss: 8153754624.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6904654848.0000 - val_loss: 7978160128.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935318528.0000 - val_loss: 8065096704.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894729728.0000 - val_loss: 7847257600.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016969728.0000 - val_loss: 7820085760.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999639040.0000 - val_loss: 8102697984.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151452160.0000 - val_loss: 9669642240.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7034013696.0000 - val_loss: 8770751488.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7241314304.0000 - val_loss: 7923300352.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7069963776.0000 - val_loss: 7928678912.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7062788096.0000 - val_loss: 7897486848.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7204978688.0000 - val_loss: 8696292352.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7140296192.0000 - val_loss: 8850620416.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6942532608.0000 - val_loss: 7878019584.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7027164160.0000 - val_loss: 8307636736.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955698176.0000 - val_loss: 7903459328.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7112979456.0000 - val_loss: 7878331904.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024013312.0000 - val_loss: 8193820672.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7103912448.0000 - val_loss: 8379905024.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7134288896.0000 - val_loss: 7889038336.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6974102016.0000 - val_loss: 7819624448.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922764288.0000 - val_loss: 8161985536.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047785472.0000 - val_loss: 9005071360.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7044623360.0000 - val_loss: 8202028544.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977606144.0000 - val_loss: 7951093760.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7146069504.0000 - val_loss: 9038829568.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7316755456.0000 - val_loss: 8773567488.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6992504320.0000 - val_loss: 7870900224.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6954604544.0000 - val_loss: 8499139584.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7025407488.0000 - val_loss: 7949276160.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7072231424.0000 - val_loss: 7850228224.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948432384.0000 - val_loss: 8068108800.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7146042368.0000 - val_loss: 7868061184.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020583424.0000 - val_loss: 8827218944.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7154572288.0000 - val_loss: 7803324416.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7046998528.0000 - val_loss: 8525787136.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999056384.0000 - val_loss: 7863632384.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7073144832.0000 - val_loss: 7820561920.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955962368.0000 - val_loss: 7847900160.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951323648.0000 - val_loss: 8385398784.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7112953344.0000 - val_loss: 8185439744.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7276033024.0000 - val_loss: 8119801856.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7041848832.0000 - val_loss: 8167592448.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7031516160.0000 - val_loss: 8771879936.0000\n",
      "Epoch 592/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6992784384.0000 - val_loss: 8047364608.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999515648.0000 - val_loss: 8690958336.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6952075776.0000 - val_loss: 7851269632.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7085758976.0000 - val_loss: 7850099712.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6917408256.0000 - val_loss: 7819599872.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6995962880.0000 - val_loss: 7896308736.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7018969088.0000 - val_loss: 7968649216.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6937856000.0000 - val_loss: 8066870272.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7030982656.0000 - val_loss: 7997434880.0000\n",
      "Epoch 601/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7142550016.0000 - val_loss: 8308156416.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6997928448.0000 - val_loss: 8239505920.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7161811968.0000 - val_loss: 7909176832.0000\n",
      "Epoch 604/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7160224256.0000 - val_loss: 9521470464.0000\n",
      "Epoch 605/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7092627968.0000 - val_loss: 7852258816.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7248620032.0000 - val_loss: 8303469056.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6972333568.0000 - val_loss: 7891023360.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7055801344.0000 - val_loss: 7815611904.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7098530816.0000 - val_loss: 8912575488.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7174390784.0000 - val_loss: 8540388864.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7063455232.0000 - val_loss: 8767297536.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7041313280.0000 - val_loss: 7854132224.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7079898624.0000 - val_loss: 7863228416.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6984236032.0000 - val_loss: 8354966528.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6979365376.0000 - val_loss: 8166806016.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7444120064.0000 - val_loss: 8050255872.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7274928640.0000 - val_loss: 7865821184.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941547520.0000 - val_loss: 7833119744.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087389696.0000 - val_loss: 7919490048.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086371840.0000 - val_loss: 8048804864.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6923430912.0000 - val_loss: 7786372096.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7013732864.0000 - val_loss: 8104833536.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052945408.0000 - val_loss: 7840588800.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6937145856.0000 - val_loss: 8058871296.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6968470528.0000 - val_loss: 8507120128.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7127461888.0000 - val_loss: 8349047808.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6965312512.0000 - val_loss: 9042851840.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7127069184.0000 - val_loss: 8027640832.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7049743872.0000 - val_loss: 7988898304.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941473792.0000 - val_loss: 8062285312.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6903100928.0000 - val_loss: 8426009088.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6931637248.0000 - val_loss: 8910248960.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7221616640.0000 - val_loss: 8328841728.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7195276800.0000 - val_loss: 8772023296.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6946181632.0000 - val_loss: 7833220096.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7228775424.0000 - val_loss: 8193429504.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6859899904.0000 - val_loss: 8345537536.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7018292224.0000 - val_loss: 7915090944.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6868783616.0000 - val_loss: 7829727232.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7105332736.0000 - val_loss: 8285467136.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6970242560.0000 - val_loss: 7825854976.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6934030336.0000 - val_loss: 7868502016.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6971177472.0000 - val_loss: 8150573056.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7101081600.0000 - val_loss: 8319324160.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7068070400.0000 - val_loss: 8195086848.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7028800512.0000 - val_loss: 8879197184.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6983815680.0000 - val_loss: 7970141184.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965766656.0000 - val_loss: 7973099008.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6914166272.0000 - val_loss: 7825070080.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7014764544.0000 - val_loss: 7921102336.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953576960.0000 - val_loss: 8662552576.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7055901184.0000 - val_loss: 8893480960.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6956790784.0000 - val_loss: 7892089344.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052179968.0000 - val_loss: 7945109504.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6921103360.0000 - val_loss: 7816876544.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6916770304.0000 - val_loss: 7790401536.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7008915968.0000 - val_loss: 8949681152.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7262376448.0000 - val_loss: 7808353280.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038346752.0000 - val_loss: 7863276032.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7000816128.0000 - val_loss: 8518394368.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001077248.0000 - val_loss: 7832746496.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962409472.0000 - val_loss: 7786410496.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7187883520.0000 - val_loss: 7907335680.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7003448320.0000 - val_loss: 7982473728.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6896501760.0000 - val_loss: 8422961152.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6992153088.0000 - val_loss: 7988864000.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6926198272.0000 - val_loss: 7952024064.0000\n",
      "Epoch 668/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964213760.0000 - val_loss: 7848087552.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056568832.0000 - val_loss: 8094909952.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7022194688.0000 - val_loss: 7874699776.0000\n",
      "Epoch 671/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077155328.0000 - val_loss: 8467154944.0000\n",
      "Epoch 672/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6932740608.0000 - val_loss: 7853555200.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897188864.0000 - val_loss: 7905564672.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6886404096.0000 - val_loss: 7816895488.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7117979648.0000 - val_loss: 7907129344.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047182336.0000 - val_loss: 8032499712.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7026723840.0000 - val_loss: 7836307968.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6982584832.0000 - val_loss: 7950615040.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7037705728.0000 - val_loss: 7913741824.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7121106944.0000 - val_loss: 9466676224.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136696832.0000 - val_loss: 8185328128.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6900251648.0000 - val_loss: 7893799424.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883039232.0000 - val_loss: 8060376576.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7098008064.0000 - val_loss: 8038184960.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6882458624.0000 - val_loss: 7989809152.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7004417536.0000 - val_loss: 8093810176.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7067899392.0000 - val_loss: 8099440640.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6958746624.0000 - val_loss: 7873721856.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7164112384.0000 - val_loss: 8026558464.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6958843904.0000 - val_loss: 8314066944.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6913474048.0000 - val_loss: 7968777216.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941389824.0000 - val_loss: 9035435008.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038875136.0000 - val_loss: 8617692160.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897801728.0000 - val_loss: 8205699584.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7068278784.0000 - val_loss: 7906550272.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7115369984.0000 - val_loss: 8258817536.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7239407616.0000 - val_loss: 8110747648.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7060782080.0000 - val_loss: 7969306112.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151836160.0000 - val_loss: 7929409536.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6898508800.0000 - val_loss: 8180569600.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7023338496.0000 - val_loss: 7957780480.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7068654592.0000 - val_loss: 7890163200.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7003041792.0000 - val_loss: 7866575360.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7101718528.0000 - val_loss: 8057121792.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7053816832.0000 - val_loss: 7819145216.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6982182400.0000 - val_loss: 8284807680.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7051823104.0000 - val_loss: 8612441088.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145246208.0000 - val_loss: 7902165504.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6971868160.0000 - val_loss: 8277560320.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100175360.0000 - val_loss: 7994228736.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7148560384.0000 - val_loss: 7879923712.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6980109312.0000 - val_loss: 8227067392.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145996288.0000 - val_loss: 8004819456.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6931445760.0000 - val_loss: 7925895168.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7051991040.0000 - val_loss: 7816025088.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964800000.0000 - val_loss: 7826302976.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6907356672.0000 - val_loss: 8025378304.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7070690304.0000 - val_loss: 8129420288.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6898422784.0000 - val_loss: 8110180352.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6916453376.0000 - val_loss: 8452020224.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6970913792.0000 - val_loss: 8163042304.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001439232.0000 - val_loss: 7818300928.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962073600.0000 - val_loss: 8105015808.0000\n",
      "Epoch 724/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7083960320.0000 - val_loss: 7963560448.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7018665984.0000 - val_loss: 8627709952.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7005585408.0000 - val_loss: 8115585024.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7004561408.0000 - val_loss: 7874696192.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6926521856.0000 - val_loss: 7890355712.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7352052736.0000 - val_loss: 7824533504.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6909786112.0000 - val_loss: 7907597824.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021021696.0000 - val_loss: 7835918336.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7036767744.0000 - val_loss: 7986080768.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7238771200.0000 - val_loss: 7874646528.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6884508160.0000 - val_loss: 7838763520.0000\n",
      "Epoch 735/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6950427648.0000 - val_loss: 8458136064.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7084917760.0000 - val_loss: 8997531648.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6932311040.0000 - val_loss: 7926579200.0000\n",
      "Epoch 738/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149601792.0000 - val_loss: 8321447424.0000\n",
      "Epoch 739/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7066681344.0000 - val_loss: 7955164672.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977406464.0000 - val_loss: 8030773248.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100226560.0000 - val_loss: 8157838336.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7026611712.0000 - val_loss: 7871120896.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6921351168.0000 - val_loss: 7967840768.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7009601536.0000 - val_loss: 7796352512.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7141988352.0000 - val_loss: 8103796224.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7027057152.0000 - val_loss: 7839631872.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7064507904.0000 - val_loss: 8168948224.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966672896.0000 - val_loss: 7907834368.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7209627136.0000 - val_loss: 7935182336.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7094015488.0000 - val_loss: 7850206208.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7023614464.0000 - val_loss: 7888694272.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7096834560.0000 - val_loss: 8690281472.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922771456.0000 - val_loss: 7901316096.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7098891264.0000 - val_loss: 8086329856.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7122011136.0000 - val_loss: 7785139200.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964771840.0000 - val_loss: 7865510400.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6952240128.0000 - val_loss: 7852095488.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6849793536.0000 - val_loss: 7835058176.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7152740864.0000 - val_loss: 8277964800.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7106275840.0000 - val_loss: 7820495360.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136176640.0000 - val_loss: 7984103936.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6923746304.0000 - val_loss: 7957907968.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024961536.0000 - val_loss: 8222660096.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7009422336.0000 - val_loss: 8704770048.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052063744.0000 - val_loss: 7861509632.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7059831808.0000 - val_loss: 7873693184.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6980019200.0000 - val_loss: 7772183552.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897660928.0000 - val_loss: 8429508096.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7010469376.0000 - val_loss: 7898265088.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7010272768.0000 - val_loss: 8219922432.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922971136.0000 - val_loss: 7861929472.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955459072.0000 - val_loss: 8222257664.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6946785792.0000 - val_loss: 7911566336.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6960962560.0000 - val_loss: 7834110464.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149552128.0000 - val_loss: 7876681216.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7092175872.0000 - val_loss: 8225756160.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7045251072.0000 - val_loss: 7971194368.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981931008.0000 - val_loss: 7898577920.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7032756736.0000 - val_loss: 9135610880.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7072385536.0000 - val_loss: 7997967360.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6844042752.0000 - val_loss: 8161189376.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6940820480.0000 - val_loss: 8258385920.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7073276928.0000 - val_loss: 8336123392.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7044769792.0000 - val_loss: 7864673792.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6950547456.0000 - val_loss: 8199990784.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897681408.0000 - val_loss: 7811515392.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7004338176.0000 - val_loss: 9117245440.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991265792.0000 - val_loss: 7917685760.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7030924288.0000 - val_loss: 7834715136.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885379072.0000 - val_loss: 8019023360.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941097472.0000 - val_loss: 8154201088.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6901893632.0000 - val_loss: 8145909248.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086416384.0000 - val_loss: 7808475648.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6982056448.0000 - val_loss: 7910454784.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6975928320.0000 - val_loss: 8013327360.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6865304064.0000 - val_loss: 7801499136.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6913245184.0000 - val_loss: 8976102400.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7571445248.0000 - val_loss: 7843677184.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100005376.0000 - val_loss: 7919447552.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991718400.0000 - val_loss: 8056684032.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993336320.0000 - val_loss: 7896283648.0000\n",
      "Epoch 802/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965362176.0000 - val_loss: 8260617728.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7003450880.0000 - val_loss: 7948382208.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021966848.0000 - val_loss: 7994936320.0000\n",
      "Epoch 805/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021519360.0000 - val_loss: 8354334720.0000\n",
      "Epoch 806/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6871757312.0000 - val_loss: 8019545600.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7217688576.0000 - val_loss: 8502014976.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7034656768.0000 - val_loss: 8457170944.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7000873984.0000 - val_loss: 8331186688.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7090958848.0000 - val_loss: 8172664832.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6839442432.0000 - val_loss: 8069819904.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6925992960.0000 - val_loss: 7903280128.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077176832.0000 - val_loss: 8641676288.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7004392448.0000 - val_loss: 7845952000.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6915953664.0000 - val_loss: 7834337792.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244008448.0000 - val_loss: 7985884672.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7134825984.0000 - val_loss: 8019882496.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050096128.0000 - val_loss: 8700079104.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7023948288.0000 - val_loss: 10269367296.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7227584000.0000 - val_loss: 7993461248.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885060608.0000 - val_loss: 7842414592.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7066527744.0000 - val_loss: 7803625472.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951220736.0000 - val_loss: 7879673856.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7061756928.0000 - val_loss: 7898037248.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029177344.0000 - val_loss: 7966017024.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918033408.0000 - val_loss: 7833477120.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7042106880.0000 - val_loss: 7823117312.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981451776.0000 - val_loss: 7872489984.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7077599744.0000 - val_loss: 7878036480.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136239104.0000 - val_loss: 7858342400.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7132468224.0000 - val_loss: 7979850240.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7085393920.0000 - val_loss: 8212888576.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6940446720.0000 - val_loss: 7899369984.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6875763712.0000 - val_loss: 7826949120.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6854715392.0000 - val_loss: 7924825088.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6845507072.0000 - val_loss: 7892322816.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951372288.0000 - val_loss: 8491170304.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7117186560.0000 - val_loss: 8097442816.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7002222592.0000 - val_loss: 8015599616.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021092352.0000 - val_loss: 7874929664.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7049245696.0000 - val_loss: 8894203904.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024288256.0000 - val_loss: 8694974464.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6899183616.0000 - val_loss: 7810438656.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7064206848.0000 - val_loss: 9159645184.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6959196160.0000 - val_loss: 8234369024.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951761920.0000 - val_loss: 8000324096.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918374912.0000 - val_loss: 8502407680.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961777664.0000 - val_loss: 7793534976.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6939493376.0000 - val_loss: 7777639936.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016141312.0000 - val_loss: 7815005184.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7160932864.0000 - val_loss: 7966850560.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883407360.0000 - val_loss: 8976285696.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075618304.0000 - val_loss: 8363871744.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6946321408.0000 - val_loss: 8001914368.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935902720.0000 - val_loss: 7761600000.0000\n",
      "Epoch 856/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883466240.0000 - val_loss: 7994863616.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6970828800.0000 - val_loss: 8161047040.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6906262016.0000 - val_loss: 8226568192.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7257680384.0000 - val_loss: 8104743936.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038276608.0000 - val_loss: 8635707392.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6919844864.0000 - val_loss: 8101260288.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938460672.0000 - val_loss: 7850162688.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183641088.0000 - val_loss: 8133997056.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6882478592.0000 - val_loss: 8002618880.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6910718976.0000 - val_loss: 8013677568.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6933859328.0000 - val_loss: 7835776512.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894407168.0000 - val_loss: 7801415680.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6917673472.0000 - val_loss: 8134505984.0000\n",
      "Epoch 869/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7169469440.0000 - val_loss: 7800029696.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999714304.0000 - val_loss: 7926970368.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035408896.0000 - val_loss: 8110907904.0000\n",
      "Epoch 872/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6889427968.0000 - val_loss: 7937711616.0000\n",
      "Epoch 873/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6998412288.0000 - val_loss: 8012697600.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955344896.0000 - val_loss: 7885816832.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6904086016.0000 - val_loss: 7816630272.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7006759936.0000 - val_loss: 7793981440.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948497920.0000 - val_loss: 7953875456.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7011710464.0000 - val_loss: 7761019392.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962023424.0000 - val_loss: 7791868928.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7008675840.0000 - val_loss: 7866741760.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7085727744.0000 - val_loss: 7849667584.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6943706112.0000 - val_loss: 8108907520.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7051532288.0000 - val_loss: 8562771968.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020167168.0000 - val_loss: 7965765632.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6863064576.0000 - val_loss: 8389569024.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7190441984.0000 - val_loss: 7979811328.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927618560.0000 - val_loss: 7929769984.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6872007680.0000 - val_loss: 7869648384.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981202944.0000 - val_loss: 7787009536.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6836792832.0000 - val_loss: 7840174592.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883928064.0000 - val_loss: 8139006464.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6998459392.0000 - val_loss: 7935694336.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6868127744.0000 - val_loss: 8141201920.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7048462848.0000 - val_loss: 7881004032.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001951744.0000 - val_loss: 8020987904.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6919449088.0000 - val_loss: 7972314112.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6942681600.0000 - val_loss: 7848446976.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6843079168.0000 - val_loss: 7791150592.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924457984.0000 - val_loss: 7856673792.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6940476928.0000 - val_loss: 8414331392.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7074912768.0000 - val_loss: 8669265920.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6963279872.0000 - val_loss: 8471059968.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6967476224.0000 - val_loss: 7885090816.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7104084992.0000 - val_loss: 8241240576.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7028581888.0000 - val_loss: 7813840384.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6855654912.0000 - val_loss: 7976999424.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6994591232.0000 - val_loss: 7853889024.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6931544064.0000 - val_loss: 7933110784.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7214146048.0000 - val_loss: 9053604864.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948365312.0000 - val_loss: 7793223168.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6904646144.0000 - val_loss: 7896739328.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6903159296.0000 - val_loss: 7803884032.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6880482304.0000 - val_loss: 7777560064.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7029404160.0000 - val_loss: 7765135872.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7022626304.0000 - val_loss: 7850291712.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894379520.0000 - val_loss: 7807281152.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6858801152.0000 - val_loss: 8368241664.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6973236736.0000 - val_loss: 7881121792.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6979024384.0000 - val_loss: 7834670592.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991182336.0000 - val_loss: 7919374848.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6923270656.0000 - val_loss: 8481123840.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7030867456.0000 - val_loss: 7805384704.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7049180672.0000 - val_loss: 8286266880.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6839813120.0000 - val_loss: 7907774976.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941572608.0000 - val_loss: 7796974592.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7095061504.0000 - val_loss: 8596040704.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6934957056.0000 - val_loss: 8010529792.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7030233088.0000 - val_loss: 8807669760.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7154332160.0000 - val_loss: 8502216704.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7067655168.0000 - val_loss: 7841506816.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6845640192.0000 - val_loss: 7805424128.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6958475776.0000 - val_loss: 7962521088.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883598848.0000 - val_loss: 7994914304.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935480832.0000 - val_loss: 7952419840.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7019959296.0000 - val_loss: 7965433344.0000\n",
      "Epoch 936/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7192380416.0000 - val_loss: 8070628864.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953252352.0000 - val_loss: 8192839680.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7116341248.0000 - val_loss: 8115609088.0000\n",
      "Epoch 939/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6896616448.0000 - val_loss: 7914080256.0000\n",
      "Epoch 940/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7083665920.0000 - val_loss: 8145826816.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6928824832.0000 - val_loss: 8033468928.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6968974336.0000 - val_loss: 8145607168.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6910721536.0000 - val_loss: 8006823424.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6898741760.0000 - val_loss: 7835415040.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935769600.0000 - val_loss: 7792491008.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951946240.0000 - val_loss: 7875867136.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6905032704.0000 - val_loss: 7955848704.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056723968.0000 - val_loss: 8514598400.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7066899968.0000 - val_loss: 7860069376.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977875968.0000 - val_loss: 9115503616.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6955401728.0000 - val_loss: 7880350720.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6997398016.0000 - val_loss: 7785589248.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6963668480.0000 - val_loss: 7889400832.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7156766720.0000 - val_loss: 7882647552.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7032101376.0000 - val_loss: 8076677120.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927438848.0000 - val_loss: 7813028352.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7003938304.0000 - val_loss: 7749269504.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894504448.0000 - val_loss: 8523889152.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966998528.0000 - val_loss: 8328016896.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024414720.0000 - val_loss: 7904311296.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6956288512.0000 - val_loss: 7805328896.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6893487616.0000 - val_loss: 8300918272.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918686720.0000 - val_loss: 7895936000.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6876979712.0000 - val_loss: 8274317312.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6949077504.0000 - val_loss: 7777532416.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6825393664.0000 - val_loss: 7806856704.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6915291136.0000 - val_loss: 8495475712.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7111151104.0000 - val_loss: 7839673344.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6996173312.0000 - val_loss: 8055249408.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6949150720.0000 - val_loss: 8029778944.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6959594496.0000 - val_loss: 7887478784.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6830989824.0000 - val_loss: 7817970176.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6895635456.0000 - val_loss: 8021839872.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6960952320.0000 - val_loss: 8450180608.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977564160.0000 - val_loss: 8386529280.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149636096.0000 - val_loss: 7897623040.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6905092608.0000 - val_loss: 7841544704.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927770624.0000 - val_loss: 7841415680.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7014923776.0000 - val_loss: 8040235008.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7402889728.0000 - val_loss: 7869412352.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870664192.0000 - val_loss: 7895566848.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6822076928.0000 - val_loss: 7940047360.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6826412544.0000 - val_loss: 7853594624.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7350365184.0000 - val_loss: 7833485312.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6915899392.0000 - val_loss: 8285451264.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6917726208.0000 - val_loss: 7965960192.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6951386624.0000 - val_loss: 7837132800.0000\n",
      "Epoch 988/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924515840.0000 - val_loss: 7971548672.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7012806144.0000 - val_loss: 8009676288.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001779200.0000 - val_loss: 8343360512.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6905198592.0000 - val_loss: 8141649408.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6988207616.0000 - val_loss: 7837483008.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7058459136.0000 - val_loss: 7796259840.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927025664.0000 - val_loss: 7888794112.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7000040960.0000 - val_loss: 8048371712.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6902145024.0000 - val_loss: 7796995072.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6926602240.0000 - val_loss: 7771735552.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6857524736.0000 - val_loss: 8100640768.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6914175488.0000 - val_loss: 7860036608.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993649152.0000 - val_loss: 8600797184.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7023877120.0000 - val_loss: 8040439808.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6901504000.0000 - val_loss: 7815369728.0000\n",
      "Epoch 1003/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016249344.0000 - val_loss: 7809016832.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7089933824.0000 - val_loss: 7934350848.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948824576.0000 - val_loss: 7931980800.0000\n",
      "Epoch 1006/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7114205184.0000 - val_loss: 7971014656.0000\n",
      "Epoch 1007/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6836707328.0000 - val_loss: 7856050176.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6952291840.0000 - val_loss: 7972818944.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7047599104.0000 - val_loss: 7811914240.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7162099200.0000 - val_loss: 7778804224.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7036602368.0000 - val_loss: 7978447360.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885807616.0000 - val_loss: 7989472256.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6916126208.0000 - val_loss: 7885209600.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6959363584.0000 - val_loss: 7914852352.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7026790912.0000 - val_loss: 7835969024.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6887650816.0000 - val_loss: 8000184832.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7043242496.0000 - val_loss: 7775534592.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6906256384.0000 - val_loss: 7850482688.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6942091264.0000 - val_loss: 8095724544.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6825863168.0000 - val_loss: 8290859520.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938946560.0000 - val_loss: 7986777088.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6956100096.0000 - val_loss: 7785568256.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6943313920.0000 - val_loss: 8062567424.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6837126656.0000 - val_loss: 7854260736.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7184742912.0000 - val_loss: 7821308928.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7043866112.0000 - val_loss: 7892134912.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6854417408.0000 - val_loss: 7911155712.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020610560.0000 - val_loss: 8037369856.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966597632.0000 - val_loss: 7932228608.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7055729664.0000 - val_loss: 7799711744.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6942032384.0000 - val_loss: 7904217088.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6954945024.0000 - val_loss: 7816119296.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7014385664.0000 - val_loss: 8265063936.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6925358080.0000 - val_loss: 8084072448.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938179072.0000 - val_loss: 8022752768.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6872425984.0000 - val_loss: 8095720448.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6912681984.0000 - val_loss: 8322333184.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6805662208.0000 - val_loss: 7853725696.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6960341504.0000 - val_loss: 7827379712.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6911912960.0000 - val_loss: 7846258688.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6994705920.0000 - val_loss: 8091195904.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6875201536.0000 - val_loss: 7844436480.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6913148416.0000 - val_loss: 8602796032.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6964204544.0000 - val_loss: 7888722432.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7089828864.0000 - val_loss: 8752171008.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6845038080.0000 - val_loss: 8099283456.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7181718528.0000 - val_loss: 8548400128.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962937856.0000 - val_loss: 8234203136.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6892652544.0000 - val_loss: 7919436800.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6908305408.0000 - val_loss: 8413236224.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6932364288.0000 - val_loss: 7950591488.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6908191232.0000 - val_loss: 7803614208.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941538304.0000 - val_loss: 8025398272.0000\n",
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6892994048.0000 - val_loss: 8016481280.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7099074560.0000 - val_loss: 7913737216.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6823627776.0000 - val_loss: 7783325184.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881368576.0000 - val_loss: 7967056896.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6815901696.0000 - val_loss: 7946132480.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7058022400.0000 - val_loss: 8386915840.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6984082432.0000 - val_loss: 8290428928.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7092260864.0000 - val_loss: 8274592256.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966523392.0000 - val_loss: 7938975744.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6867283456.0000 - val_loss: 7987033088.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6784920064.0000 - val_loss: 8717562880.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7081308672.0000 - val_loss: 7822044160.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6840563712.0000 - val_loss: 7920421376.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6847412736.0000 - val_loss: 7975122944.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993761280.0000 - val_loss: 8984915968.0000\n",
      "Epoch 1069/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7021183488.0000 - val_loss: 7773830656.0000\n",
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6925363712.0000 - val_loss: 7830488064.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6900435968.0000 - val_loss: 7872204800.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966220288.0000 - val_loss: 7880104448.0000\n",
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881028608.0000 - val_loss: 7892563456.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6857869824.0000 - val_loss: 8016014336.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6921545216.0000 - val_loss: 8105318400.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6871381504.0000 - val_loss: 8138098176.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6848543232.0000 - val_loss: 7766553600.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6980751872.0000 - val_loss: 7839040000.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6872333824.0000 - val_loss: 8259410944.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7024648704.0000 - val_loss: 7739548672.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6911534080.0000 - val_loss: 8030696448.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6866563584.0000 - val_loss: 7947428352.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6848999424.0000 - val_loss: 8142016512.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881973760.0000 - val_loss: 7756486656.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7031768064.0000 - val_loss: 7915095040.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6884473856.0000 - val_loss: 7792552448.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6928340480.0000 - val_loss: 8142553600.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6843587584.0000 - val_loss: 8016199680.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6982171136.0000 - val_loss: 8100678656.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7001373184.0000 - val_loss: 8133549568.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7356764160.0000 - val_loss: 7832738816.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6944617472.0000 - val_loss: 7818663936.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7007424000.0000 - val_loss: 8427214848.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6910504448.0000 - val_loss: 7855069184.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6773216768.0000 - val_loss: 8194015232.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6884725248.0000 - val_loss: 8249792512.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6960617984.0000 - val_loss: 7811109376.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6911262208.0000 - val_loss: 7909043712.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6875588608.0000 - val_loss: 7851254784.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7137437696.0000 - val_loss: 7829211136.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6799297536.0000 - val_loss: 7925527040.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6978014720.0000 - val_loss: 8165351936.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961876992.0000 - val_loss: 8028991488.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7154377728.0000 - val_loss: 8038756352.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7251351552.0000 - val_loss: 7785217536.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6880011264.0000 - val_loss: 7979053056.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6976841728.0000 - val_loss: 8080908800.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6875820544.0000 - val_loss: 7900680704.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6873612288.0000 - val_loss: 7845753344.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6864605184.0000 - val_loss: 8140256256.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881804800.0000 - val_loss: 7848391680.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6841324032.0000 - val_loss: 7965295104.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6783569920.0000 - val_loss: 7923599872.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7103939072.0000 - val_loss: 7739574272.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924106752.0000 - val_loss: 7926301184.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6827967488.0000 - val_loss: 8024144896.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6846309376.0000 - val_loss: 7870487552.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087305216.0000 - val_loss: 8158866432.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7207361536.0000 - val_loss: 8349588480.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6805921280.0000 - val_loss: 8103824896.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6775261184.0000 - val_loss: 7915247104.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881290752.0000 - val_loss: 7778715136.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6902512128.0000 - val_loss: 7854794752.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6907842560.0000 - val_loss: 8306381312.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035286528.0000 - val_loss: 7794754048.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6905048576.0000 - val_loss: 7806123008.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6989340672.0000 - val_loss: 8492405760.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991026688.0000 - val_loss: 7872494080.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6810363392.0000 - val_loss: 7862791680.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6874933760.0000 - val_loss: 8498717696.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885987328.0000 - val_loss: 7830154752.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6969069056.0000 - val_loss: 7917900800.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6866216448.0000 - val_loss: 7971460608.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7005979648.0000 - val_loss: 7813078016.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6831506432.0000 - val_loss: 8568308224.0000\n",
      "Epoch 1136/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7045508608.0000 - val_loss: 8144606720.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136407040.0000 - val_loss: 8099288576.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7226142208.0000 - val_loss: 8528093184.0000\n",
      "Epoch 1139/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6803736576.0000 - val_loss: 8074206720.0000\n",
      "Epoch 1140/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6930322944.0000 - val_loss: 8379952128.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6821465088.0000 - val_loss: 7846422016.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6820468736.0000 - val_loss: 7898249216.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6856829440.0000 - val_loss: 8063038976.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6959737344.0000 - val_loss: 7949317632.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881726464.0000 - val_loss: 7746889216.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075764736.0000 - val_loss: 7987951104.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7073079808.0000 - val_loss: 7837853184.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050486272.0000 - val_loss: 7890175488.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7165950976.0000 - val_loss: 7887640064.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6919783424.0000 - val_loss: 7888508928.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7049023488.0000 - val_loss: 7999639552.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935865344.0000 - val_loss: 7786799616.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881224192.0000 - val_loss: 7834129408.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918404096.0000 - val_loss: 7893358592.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6969942016.0000 - val_loss: 7790874112.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7066759168.0000 - val_loss: 7899015680.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6873468416.0000 - val_loss: 8452051456.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7158681088.0000 - val_loss: 7851464192.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6884493312.0000 - val_loss: 7846946816.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6758302720.0000 - val_loss: 7785760768.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6889840128.0000 - val_loss: 7853321728.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6896640000.0000 - val_loss: 7914303488.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6867872768.0000 - val_loss: 7859115008.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6800103424.0000 - val_loss: 8118433792.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6921188352.0000 - val_loss: 7841623040.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7130718720.0000 - val_loss: 8305445888.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6811177984.0000 - val_loss: 8047671296.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7044493312.0000 - val_loss: 7976053760.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7031481344.0000 - val_loss: 9315589120.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6914421248.0000 - val_loss: 8091379712.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6853937664.0000 - val_loss: 8094115840.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7020161536.0000 - val_loss: 7889282048.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999947776.0000 - val_loss: 8082954240.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894654464.0000 - val_loss: 7790541824.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6864387584.0000 - val_loss: 7795395584.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6891922432.0000 - val_loss: 8078734336.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6862964224.0000 - val_loss: 7868816384.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7025668096.0000 - val_loss: 8269580288.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7045365248.0000 - val_loss: 7862757888.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6900727808.0000 - val_loss: 7977624576.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6945214464.0000 - val_loss: 7858132992.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6973537792.0000 - val_loss: 7779928064.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6840495616.0000 - val_loss: 7809853440.0000\n",
      "Epoch 1184/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6899373568.0000 - val_loss: 8130812416.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6929299968.0000 - val_loss: 7840290304.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6974489088.0000 - val_loss: 8077103104.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6840976384.0000 - val_loss: 8634114048.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7130804224.0000 - val_loss: 8006125568.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7079929856.0000 - val_loss: 7861017600.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6824372736.0000 - val_loss: 7822211584.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6917584384.0000 - val_loss: 8748485632.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6909024768.0000 - val_loss: 8137036800.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6994733568.0000 - val_loss: 7851457024.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7087219712.0000 - val_loss: 7843991552.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6833330176.0000 - val_loss: 8031026176.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6983961088.0000 - val_loss: 8655239168.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6879812608.0000 - val_loss: 7886945280.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6952702976.0000 - val_loss: 7794919936.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6828072960.0000 - val_loss: 8999772160.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7099110912.0000 - val_loss: 7962379264.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6803405312.0000 - val_loss: 7989686784.0000\n",
      "Epoch 1202/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6797031424.0000 - val_loss: 8964386816.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7376271872.0000 - val_loss: 7945951744.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977849856.0000 - val_loss: 7767255040.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918102528.0000 - val_loss: 8019018240.0000\n",
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965427200.0000 - val_loss: 7849658880.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961029632.0000 - val_loss: 8108006400.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6871326720.0000 - val_loss: 7851408384.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870641664.0000 - val_loss: 7870042112.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6802198016.0000 - val_loss: 7813922816.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6885713920.0000 - val_loss: 7805156352.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052554752.0000 - val_loss: 7910051840.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6862150656.0000 - val_loss: 7955036160.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6772023296.0000 - val_loss: 7886167040.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965144576.0000 - val_loss: 8466785792.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991457792.0000 - val_loss: 7827127808.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6834880000.0000 - val_loss: 7787713536.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938745856.0000 - val_loss: 7770656768.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6850263552.0000 - val_loss: 7819053056.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6998409728.0000 - val_loss: 7915325952.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6815864832.0000 - val_loss: 8105197056.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924390400.0000 - val_loss: 7785652224.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6843109376.0000 - val_loss: 8572185600.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7134606336.0000 - val_loss: 8651959296.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056960512.0000 - val_loss: 7952951296.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6868473856.0000 - val_loss: 7988297728.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7118709760.0000 - val_loss: 9435207680.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7012777472.0000 - val_loss: 7810120704.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6737320448.0000 - val_loss: 7914868224.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6871388672.0000 - val_loss: 8004098560.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6983949312.0000 - val_loss: 7907353088.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6998968832.0000 - val_loss: 8165402624.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6824795136.0000 - val_loss: 7777584640.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6875717120.0000 - val_loss: 8004407808.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7034119168.0000 - val_loss: 8043692544.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6848673792.0000 - val_loss: 7829194240.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6865913856.0000 - val_loss: 8036022784.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6886971392.0000 - val_loss: 8589977600.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6807053312.0000 - val_loss: 7914685440.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6811597312.0000 - val_loss: 7897610240.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6991033344.0000 - val_loss: 7840184832.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6791371264.0000 - val_loss: 8013638656.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7058249728.0000 - val_loss: 7930476032.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6923368448.0000 - val_loss: 7925021184.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6791028736.0000 - val_loss: 8159843840.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870126080.0000 - val_loss: 8138203136.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7077444608.0000 - val_loss: 9679001600.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6920258560.0000 - val_loss: 7912401408.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6823693824.0000 - val_loss: 7793164288.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6830775808.0000 - val_loss: 7841734656.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6989726720.0000 - val_loss: 7898885632.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6805444608.0000 - val_loss: 8563529216.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6876207616.0000 - val_loss: 7911746560.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7040980480.0000 - val_loss: 7774416384.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6852957184.0000 - val_loss: 7885938688.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6799352832.0000 - val_loss: 7979179008.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6807909376.0000 - val_loss: 8180421120.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961135616.0000 - val_loss: 8018384896.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6966036480.0000 - val_loss: 7767299072.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6802204160.0000 - val_loss: 8467249664.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7110388224.0000 - val_loss: 8526029824.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6944526848.0000 - val_loss: 7781708800.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6903504384.0000 - val_loss: 7777526272.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6932420608.0000 - val_loss: 7777434112.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938819072.0000 - val_loss: 8060715008.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981865472.0000 - val_loss: 7829433344.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6835814912.0000 - val_loss: 7951934464.0000\n",
      "Epoch 1268/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 6937924608.0000 - val_loss: 7892398592.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 6824867840.0000 - val_loss: 8208796672.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7048629248.0000 - val_loss: 7852086272.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7145068544.0000 - val_loss: 9059426304.0000\n",
      "Epoch 1272/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6833461760.0000 - val_loss: 7862306816.0000\n",
      "Epoch 1273/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7148859904.0000 - val_loss: 7905805824.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6887470592.0000 - val_loss: 7843848704.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6808151040.0000 - val_loss: 7917775872.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6927568384.0000 - val_loss: 7920206848.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883948544.0000 - val_loss: 7982746112.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922738688.0000 - val_loss: 7860002816.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6965007360.0000 - val_loss: 8306071552.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6776733696.0000 - val_loss: 8123828224.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7054270464.0000 - val_loss: 7923037696.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6780234752.0000 - val_loss: 7880293376.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6866671104.0000 - val_loss: 7741244416.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6817056768.0000 - val_loss: 7819899904.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6805705728.0000 - val_loss: 7841341440.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6984210432.0000 - val_loss: 7960788992.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7193122304.0000 - val_loss: 7863630848.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7151928320.0000 - val_loss: 8069362176.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6906801152.0000 - val_loss: 8099646464.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935248896.0000 - val_loss: 7903394816.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050407936.0000 - val_loss: 7758396416.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6862280704.0000 - val_loss: 7829925376.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6825708032.0000 - val_loss: 7771616256.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6902245376.0000 - val_loss: 7832797696.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918106624.0000 - val_loss: 7767174656.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6865835520.0000 - val_loss: 8014013440.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6833389568.0000 - val_loss: 8046927360.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870811136.0000 - val_loss: 7826296320.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6758087680.0000 - val_loss: 7892607488.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7016282624.0000 - val_loss: 8081952768.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941996544.0000 - val_loss: 7852861952.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6908826624.0000 - val_loss: 7935777792.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6812788224.0000 - val_loss: 7878615040.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6819848192.0000 - val_loss: 8570150912.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6957490688.0000 - val_loss: 8132622848.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6880108544.0000 - val_loss: 7810578432.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6807600128.0000 - val_loss: 8271897600.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038574592.0000 - val_loss: 7842783744.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6856620544.0000 - val_loss: 8070225408.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6837833216.0000 - val_loss: 7772182528.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6981199872.0000 - val_loss: 7911446016.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6922266624.0000 - val_loss: 8468023296.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6843950592.0000 - val_loss: 7842742272.0000\n",
      "Epoch 1314/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6997388288.0000 - val_loss: 7791176192.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948630528.0000 - val_loss: 8327118848.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7038543872.0000 - val_loss: 7832988672.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6879918080.0000 - val_loss: 7842827264.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6949890560.0000 - val_loss: 8066684416.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6824028160.0000 - val_loss: 7917140480.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6784482816.0000 - val_loss: 8111505408.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6973893632.0000 - val_loss: 7828533248.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6881456128.0000 - val_loss: 7838768128.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6807152640.0000 - val_loss: 8141470720.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6780040704.0000 - val_loss: 7789077504.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6750445568.0000 - val_loss: 7757030912.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7049542656.0000 - val_loss: 8558745088.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6901864448.0000 - val_loss: 7833292800.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6721767424.0000 - val_loss: 7962257920.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870016512.0000 - val_loss: 7884137472.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6829371392.0000 - val_loss: 7830661120.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7019043328.0000 - val_loss: 8783749120.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6917328896.0000 - val_loss: 7758750208.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6829729280.0000 - val_loss: 8097645056.0000\n",
      "Epoch 1334/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6986515456.0000 - val_loss: 7759525376.0000\n",
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6811993600.0000 - val_loss: 7865998848.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7143971328.0000 - val_loss: 8076026368.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894849024.0000 - val_loss: 8732217344.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6802326016.0000 - val_loss: 7975155712.0000\n",
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6735746560.0000 - val_loss: 7831885312.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7056524800.0000 - val_loss: 7900830208.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6806617600.0000 - val_loss: 7807426560.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6852233728.0000 - val_loss: 8031234048.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7262807552.0000 - val_loss: 8209631744.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7043959296.0000 - val_loss: 7777949184.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6827439104.0000 - val_loss: 8422861312.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6810866176.0000 - val_loss: 7772597760.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6815376896.0000 - val_loss: 7946188800.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6836017664.0000 - val_loss: 7797453312.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6856372736.0000 - val_loss: 7838712832.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6861263872.0000 - val_loss: 8482867712.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6987113472.0000 - val_loss: 7846279680.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6896517632.0000 - val_loss: 8030858240.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6935377408.0000 - val_loss: 7789796864.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6800372736.0000 - val_loss: 7970826752.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6925434880.0000 - val_loss: 8018563584.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6993341440.0000 - val_loss: 7888282112.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086899200.0000 - val_loss: 8098630144.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6893072896.0000 - val_loss: 7793721856.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6948546048.0000 - val_loss: 7982571520.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6967526912.0000 - val_loss: 8014744064.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6928032768.0000 - val_loss: 7861656576.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7010377728.0000 - val_loss: 7829668864.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6924619776.0000 - val_loss: 8175302656.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6863210496.0000 - val_loss: 7920775680.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6894051328.0000 - val_loss: 7871216128.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6806508544.0000 - val_loss: 8132768256.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6888742400.0000 - val_loss: 7874004480.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6904795136.0000 - val_loss: 7826897408.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6820241408.0000 - val_loss: 8137696768.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6767363072.0000 - val_loss: 7853024768.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6861970432.0000 - val_loss: 7873189376.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6787680768.0000 - val_loss: 7773497344.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6977116160.0000 - val_loss: 7880462848.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6870954496.0000 - val_loss: 8079982592.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6876981248.0000 - val_loss: 8634194944.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953596416.0000 - val_loss: 8323836928.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6817963520.0000 - val_loss: 7900966912.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6783453184.0000 - val_loss: 7883495936.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6873091584.0000 - val_loss: 8019189760.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6888440832.0000 - val_loss: 7840538112.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7025695744.0000 - val_loss: 8551758848.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6923443712.0000 - val_loss: 7805937664.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6837641728.0000 - val_loss: 7850464768.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6677625344.0000 - val_loss: 7837513728.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6862803968.0000 - val_loss: 7976106496.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6868412416.0000 - val_loss: 7806289408.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6928655872.0000 - val_loss: 7884737536.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6945710592.0000 - val_loss: 8277511680.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6909300736.0000 - val_loss: 7777802752.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6814784000.0000 - val_loss: 8067076608.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953972224.0000 - val_loss: 7762306048.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6795129856.0000 - val_loss: 8447286784.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6950955520.0000 - val_loss: 8253952000.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6814853120.0000 - val_loss: 7902347264.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6766358528.0000 - val_loss: 7808413184.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6961548800.0000 - val_loss: 7807973376.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6757068800.0000 - val_loss: 7928005120.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6734173696.0000 - val_loss: 7849900544.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7175587840.0000 - val_loss: 8100563968.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6811092480.0000 - val_loss: 7896327680.0000\n",
      "Epoch 1401/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6874881536.0000 - val_loss: 7825120256.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6996426752.0000 - val_loss: 7972382720.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7052222464.0000 - val_loss: 7873396736.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7014659072.0000 - val_loss: 8303863808.0000\n",
      "Epoch 1405/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6793255424.0000 - val_loss: 8704675840.0000\n",
      "Epoch 1406/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6933038080.0000 - val_loss: 8364503040.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6975609856.0000 - val_loss: 7845393920.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6931943424.0000 - val_loss: 7962571264.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6932390912.0000 - val_loss: 8448862720.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7216791552.0000 - val_loss: 8054416384.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6895145472.0000 - val_loss: 8918996992.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6775183872.0000 - val_loss: 7967778816.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6820179968.0000 - val_loss: 7769196032.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6767421952.0000 - val_loss: 7863370752.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6724755968.0000 - val_loss: 8091165696.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6854654464.0000 - val_loss: 8864105472.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962997248.0000 - val_loss: 7757712384.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6816954368.0000 - val_loss: 8457873920.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6787272704.0000 - val_loss: 7829044224.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6891498496.0000 - val_loss: 7998366208.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6851689472.0000 - val_loss: 7914508288.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6857700352.0000 - val_loss: 7872798208.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6931474944.0000 - val_loss: 7850074624.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6844577280.0000 - val_loss: 7780043264.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6861178880.0000 - val_loss: 7887001600.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6863027200.0000 - val_loss: 7846659584.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6953074688.0000 - val_loss: 7907350528.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6920773632.0000 - val_loss: 7814566400.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6791795200.0000 - val_loss: 7993357824.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6851017728.0000 - val_loss: 8650374144.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6858648064.0000 - val_loss: 7974453760.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6827484672.0000 - val_loss: 7813234176.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6972270592.0000 - val_loss: 8217807360.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035142144.0000 - val_loss: 8021011968.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6814377472.0000 - val_loss: 7901563392.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6851542528.0000 - val_loss: 8225059328.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6750199296.0000 - val_loss: 7744165888.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6848331776.0000 - val_loss: 8437118464.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962045952.0000 - val_loss: 8685291520.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6743916032.0000 - val_loss: 7866055680.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6752758784.0000 - val_loss: 8079234048.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7009452544.0000 - val_loss: 9535801344.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7128419328.0000 - val_loss: 7928143872.0000\n",
      "Epoch 1444/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6825966080.0000 - val_loss: 7977995776.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6902935552.0000 - val_loss: 7970778624.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6887721984.0000 - val_loss: 8206069760.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7012913664.0000 - val_loss: 7874404864.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6753325568.0000 - val_loss: 7755282432.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6763681280.0000 - val_loss: 7844109824.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6861359616.0000 - val_loss: 7917689344.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6889104384.0000 - val_loss: 7951781888.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6879659520.0000 - val_loss: 7786993664.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6943651840.0000 - val_loss: 7749350912.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6897669120.0000 - val_loss: 8315807232.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6910682112.0000 - val_loss: 7840991232.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7251552256.0000 - val_loss: 7985581568.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6912396800.0000 - val_loss: 7880455680.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6790788096.0000 - val_loss: 8515909120.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6821632512.0000 - val_loss: 7995570688.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6901099520.0000 - val_loss: 7949415424.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6941265408.0000 - val_loss: 7977681920.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6825475584.0000 - val_loss: 8397584384.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6891044864.0000 - val_loss: 7879002112.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6842011136.0000 - val_loss: 7976673280.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6856184832.0000 - val_loss: 7965055488.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6866685952.0000 - val_loss: 7842339328.0000\n",
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6855030272.0000 - val_loss: 7926287872.0000\n",
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938309632.0000 - val_loss: 7927226368.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6943418880.0000 - val_loss: 7790542848.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6772979712.0000 - val_loss: 8059036672.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6793880576.0000 - val_loss: 8168154624.0000\n",
      "Epoch 1472/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6848584704.0000 - val_loss: 7758186496.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6891388928.0000 - val_loss: 7949694464.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6818696192.0000 - val_loss: 9964940288.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6908003840.0000 - val_loss: 7872035840.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6891656192.0000 - val_loss: 7901608960.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6978584064.0000 - val_loss: 7958251008.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6918110208.0000 - val_loss: 9290675200.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6938062336.0000 - val_loss: 8094238208.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6842068480.0000 - val_loss: 7983181312.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6962064384.0000 - val_loss: 7861866496.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6905294848.0000 - val_loss: 8329411584.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7050190848.0000 - val_loss: 8296211456.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7035870208.0000 - val_loss: 8204023808.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6980040704.0000 - val_loss: 7813804032.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6719794688.0000 - val_loss: 7819921408.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6781052928.0000 - val_loss: 8524409344.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6912691712.0000 - val_loss: 8101733888.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6861145088.0000 - val_loss: 7813645312.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6777423872.0000 - val_loss: 8048644096.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6913167872.0000 - val_loss: 7800460800.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6883006464.0000 - val_loss: 10027220992.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6963956224.0000 - val_loss: 7760783360.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6847054336.0000 - val_loss: 8466452480.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6999281152.0000 - val_loss: 7785679360.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6804690432.0000 - val_loss: 7791709696.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6787207680.0000 - val_loss: 7872556544.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6759932928.0000 - val_loss: 8651062272.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6915299328.0000 - val_loss: 7839313920.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6689944576.0000 - val_loss: 7907405312.0000\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n",
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81dcd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "856d9610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABZ+ElEQVR4nO2dd5wURfbAv28DOWcEJQgKCIqKYEQwYI7nnSjqmY7jDGc6T9RTOcPPeHqecuYsBvTMIGAkKCJBcs4seclpYUP9/ujpmZ6e7p7u2Uk71Pfz2c/OdFdXv+7pfvXq1atXopRCo9FoNLlLXqYF0Gg0Gk1q0Ypeo9Fochyt6DUajSbH0Ypeo9Fochyt6DUajSbH0Ypeo9FocpysVfQi8rqIbBCR2T7K9haRaSJSJiKX2Pb9UUQWhf7+mDqJNRqNJjvJWkUPvAmc6bPsSuBq4D3rRhFpBDwA9AJ6Ag+ISMPkiajRaDTZT9YqeqXUOGCzdZuIHCwio0RkqoiMF5FOobLLlVIzgQpbNWcA3yilNiultgDf4L/x0Gg0mpygINMCBORlYJBSapGI9AL+C5ziUb4VsMryvSi0TaPRaPYbqoyiF5E6wPHARyJibq4e7zCHbTrng0aj2a+oMooew820VSnVPcAxRUAfy/fWwI/JE0mj0Wiyn6z10dtRSm0HlonI7wHE4Ig4h40G+olIw9AgbL/QNo1Go9lvyFpFLyLvAxOBQ0WkSESuAwYA14nIDGAOcEGo7DEiUgT8HnhJROYAKKU2Aw8Bk0N/D4a2aTQazX6D6DTFGo1Gk9tkrUWv0Wg0muSQlYOxTZo0UW3bts20GBqNRlNlmDp1arFSqqnTvqxU9G3btmXKlCmZFkOj0WiqDCKywm2fdt1oNBpNjqMVvUaj0eQ4WtFrNBpNjpOVPnonSktLKSoqoqSkJNOiZDU1atSgdevWFBYWZloUjUaTJVQZRV9UVETdunVp27Ytllw3GgtKKTZt2kRRURHt2rXLtDgajSZLqDKum5KSEho3bqyVvAciQuPGjXWvR6PRRFFlFD2glbwP9D3SaDR2qpSi12iqJMvGQ/GiTEuh2Y/Rij4AderUybQImqrIW+fC8z0yLYVmP0Yreo1Go8lxtKJPAKUUd955J127dqVbt258+OGHAKxdu5bevXvTvXt3unbtyvjx4ykvL+fqq68Ol33mmWcyLL1Go9nfqDLhlVb++eUc5q7ZntQ6uxxQjwfOO8xX2U8++YTp06czY8YMiouLOeaYY+jduzfvvfceZ5xxBvfeey/l5eXs3r2b6dOns3r1ambPng3A1q1bkyq3RqPRxENb9AkwYcIELrvsMvLz82nevDknn3wykydP5phjjuGNN95gyJAhzJo1i7p169K+fXuWLl3KzTffzKhRo6hXr16mxddoNPsZVdKi92t5pwq3xVp69+7NuHHjGDFiBFdeeSV33nknV111FTNmzGD06NEMHTqU4cOH8/rrr6dZYo1Gsz+jLfoE6N27Nx9++CHl5eVs3LiRcePG0bNnT1asWEGzZs3405/+xHXXXce0adMoLi6moqKC3/3udzz00ENMmzYt0+JrNJr9jCpp0Weaiy66iIkTJ3LEEUcgIjzxxBO0aNGCt956iyeffJLCwkLq1KnD22+/zerVq7nmmmuoqKgA4NFHH82w9BqNZn8jK9eM7dGjh7IvPDJv3jw6d+6cIYmqFvpeZRlD6of+b8usHJqcRkSmKqUcJ2xo140meWxZDrM+zrQUGo3GhnbdaJLHK6fA7k3Q7ZJMS6LRaCxoi16TPHZvyrQEGo3GgbiKXkReF5ENIjLbZb+IyH9EZLGIzBSRoyz7zhSRBaF9g5MpuEaj0eQMe7amtHo/Fv2bwJke+88COob+BgIvAIhIPjA0tL8LcJmIdKmMsBqNRpNzrJgIj7eBeV+l7BRxFb1Sahyw2aPIBcDbyuAXoIGItAR6AouVUkuVUvuAD0JlNRqNRmOyJjS3ZsVPKTtFMnz0rYBVlu9FoW1u2x0RkYEiMkVEpmzcuDEJYmk0Go0GkqPonZY0Uh7bHVFKvayU6qGU6tG0adMkiJVZvHLXL1++nK5duwavtGQbVJRXQiqNRpMV/PwcLByTttMlI7yyCDjQ8r01sAao5rJdkwilu2HzUqjZCBq2ybQ0Go2mMoz5h/E/TZPokqHovwBuEpEPgF7ANqXUWhHZCHQUkXbAaqA/cHkSzgdfD4Z1s5JSVZgW3eCsx1x333XXXbRp04YbbrgBgCFDhiAijBs3ji1btlBaWsrDDz/MBRcEG4YoKSnhL3/5C1OmTKGgoICnn36avn37MmfOHK655hr27dtHRUUF/3v/LQ6ovoc//PGPFG3YQnl5Offddx+XXnpppS5bo9HkPnEVvYi8D/QBmohIEfAAUAiglHoRGAmcDSwGdgPXhPaVichNwGggH3hdKTUnBdeQFvr378+tt94aVvTDhw9n1KhR3HbbbdSrV4/i4mKOPfZYzj///EALdA8dOhSAWbNmMX/+fPr168fChQt58cUXueWWWxgwYAD79u2jfPc2Rn70Fge0aMaIb34EYNu2LJ1SrxToRco1mqwhrqJXSl0WZ78CbnTZNxKjIUguHpZ3qjjyyCPZsGEDa9asYePGjTRs2JCWLVty2223MW7cOPLy8li9ejXr16+nRYsWvuudMGECN998MwCdOnWiTZs2LFy4kOOOO45HHnmEoqIiLr74Yjoe1JJunTrwt4f/zV133cW5557LSSedlKrL1Wg0OYSeGRuASy65hI8//pgPP/yQ/v37M2zYMDZu3MjUqVOZPn06zZs3p6SkJFCdbknlLr/8cr744gtq1qzJGWecwfc/jOWQg9sw9ZtP6NatG3fffTcPPvhgMi4r+WRhojyNZn9G57oJQP/+/fnTn/5EcXExY8eOZfjw4TRr1ozCwkJ++OEHVqxYEbjO3r17M2zYME455RQWLlzIypUrOfTQQ1m6dCnt27fnr3/9K0uXLmXm7Nl0alZIo6YtueKKK6hTpw5vvvlm8i9So9GklzQYRlrRB+Cwww5jx44dtGrVipYtWzJgwADOO+88evToQffu3enUqVPgOm+44QYGDRpEt27dKCgo4M0336R69ep8+OGHvPvuuxQWFtKiRQvuv+t2Jv/wJXdecTN51WpSWFjICy+8kIKr1Gg0uYZW9AGZNSsS7dOkSRMmTpzoWG7nzp2udbRt2za8WHiNGjUcLfO7776bu+++O7Jh707O6HM8Z5x+OjQ9JDHh04Z23Wg0vklD4IL20Vc5tBLVaDTB0BZ9Cpk1axZXXnll1Lbq1aszadKk4JVVpXBFPRir0WQVVUrRK6UCxahnmm7dujF9+vS0njMbl4bUaDSZpcq4bmrUqMGmTZu0IvNAKcWmTZuoUaNGpiXJ8Pk1Go2VKmPRt27dmqKiIvbbzJZle2HnBsivDsUVrsVq1KhB69at0yiYRqPJdqqMoi8sLKRdu3aZFiNzFE2F//0BDjgKBv6QaWk0Gk0Vosq4bjQmVcAtot1rGk1WoRV9VaHqjEEnzoZ5sPKXTEuhqUoMqQ/fP5xpKbIereirDCFNn2pr+c1zYepblawkQRn/eyy8fkYlz63Z7xj3ZKYlyHq0oq8qmGGlyn0gNiksHw9f/jW159BoNBHS4OrUir7KUIV8N0Ef3HFPGl1wjUaTErSir3Lk4ECn9rFq9md0rhtNmCo0I1ij0WQXWtFXNaqEQV8lhNRo9ht8KXoROVNEFojIYhEZ7LC/oYh8KiIzReRXEelq2bdcRGaJyHQRmZJM4fcvtEWv0VQplDJmtGcBcRW9iOQDQ4GzgC7AZSLSxVbsHmC6Uupw4CrgWdv+vkqp7kqpHkmQef8k7LqpAtZyqqMISrYbMfcaTTYz5XV4uBlsK8q0JL4s+p7AYqXUUqXUPuAD4AJbmS7AdwBKqflAWxFpnlRJ93vSFEdfFXjnQiPmXqPJZuZ8avzfvNS7XJaEV7YCVlm+F4W2WZkBXAwgIj2BNoCZWUsBY0RkqogMrJy4miph0adaxtVTU1u/RpNj+FH0Ts5h+5v8GNBQRKYDNwO/AWWhfScopY7CcP3cKCK9HU8iMlBEpojIlP02Q6UXoi36pLFuFpTty7QUmlzH77uaJeGVRcCBlu+tgTXWAkqp7Uqpa5RS3TF89E2BZaF9a0L/NwCfYriCYlBKvayU6qGU6tG0adOg17EfoAdjk8K2InjxRPj6zkxLotGkDT+KfjLQUUTaiUg1oD/whbWAiDQI7QO4HhinlNouIrVFpG6oTG2gHzA7eeLvj1QBiz6bex17thj/V03OrByaxJj6JmxZkWkp/JFFc1/iKnqlVBlwEzAamAcMV0rNEZFBIjIoVKwzMEdE5mO4aG4JbW8OTBCRGcCvwAil1KhkX0TG2boK3jgH9mxN4UmyWHlqNOlg3y748hYj8V5VwK/BkwbDyNfCI0qpkcBI27YXLZ8nAh0djlsKHFFJGbOf8U/Bigkw5xPocW1qz5XN1nKYKiBjFllbGp+YCf32bA59rwLPWZagZ8ZWFcIPtX64k4JWEpr9CK3ok0k6lEdVUFBZLaO25HOGrH7OrGT+mdOKvspQVR7qbEffxypLjGKvKr9lHDmzJLxS45e0+H2rysOt0WiyBa3oqwpVppsKvhqjDfPgt2GVPE0i9yTz3WiNhf8eB8P+kNixVeadyPwz5yvqRpNFVJmHOw5mrpojByReh1KV6EXlyH2s6myYa/wFogol+IvH1pVZk+tG45e0KOEq8HDnSmOkyVJy6Pka9vu0nEYr+ipD6OHWStRCZe5F5rvTmkpSZd4FDzn37UqLBFrRJ5OqPhibtBenKryAaZKxyiijqoRupIOiFX0ySeVLrWP0Y0lEXj0jNoeoKs+rxzNXqXEm/2hFX9Woasp4f0f/XknEdi9z5d7qwdgqRkpb5io00Ju2FzBHXnSNP3JFsVtJUw9TK/pkUtWjbqrai1Ql5HWRcf1c2LQkvaLkHNn++/uQL03PsFb0VQXzgVDA7s1QUZGKk6Sgzv2Aigr3F9Zt+wvHwXNHpU6mnEQ/n4miFX0y+f7h1C9Rt2sDPNEOxj4ev+yOdTCkPsz4ILUyZYwsefEfbAgj9YpVKcfeaGZ9j86nW0YPxlYVQj/Uns0w7a3UnqqsxPg//6v4ZYsXGf+nveOv7mS9OFn/ApJ8GSe/YjSq24rsJ0ruebxY85shw4b56TtnRsn25yx75NOKPilYftDy0tSfwy/hBcX9unmy58H0RTbmutm4ILX1ezH7f8b/RaMzJ4MmK9GKPulkkbIU8+fNIpkyTprvRVXo3VRVcuXe6vDKqoLFSkzVjxZTrR/LNKBFX+VmxmbBi26/ZzH+1iTKuG42zP4kefVVNfzko9+3G544GBZ9mxaRfJEFk/R8KXoROVNEFojIYhEZ7LC/oYh8KiIzReRXEenq91hNCjEtet8KPAsUp5UJ/4bp77nvt17Xs0fAp4Pcy4axvHRFU2H+iESli5Uh1bx4Anx8TfrOl3X4uNebl8DuYvj2gdSL45cs6HnEVfQikg8MBc4CugCXiUgXW7F7gOlKqcOBq4BnAxybY6TqR02Hjz5JJOvB/vYB+Owv/spuWQ4z3g9QuYJXT4EPLk9EMo9qsyAyJAsUS1rYX64zCfix6HsCi5VSS5VS+4APgAtsZboA3wEopeYDbUWkuc9jNSnDlrd74RjvCJxsenHmj/RRKA3yrp0BRVMqIUMW3dOqxJIfYp+BbHo+gxDPdZMl4ZWtgFWW70WhbVZmABcDiEhPoA3Q2uexhI4bKCJTRGTKxo0b/UmfjaTMR18Ziz507Hu/hy9u8jpJ8HOkqp4x91a+Dk98vlwv9YZXT3Xf72TBr/nNvxhFU6Gi3H95P6RKcWxZAW+eCyXbUlO/lXcuhA8us20M3WuxGTBVGpU1g7FOT41dsseAhiIyHbgZ+A0o83mssVGpl5VSPZRSPZo2bepDrGwlix6+TLluglCZh7xSL0iKGrWf/g0v94FVk0O745zn1VNg/L+SJEuK+fExWD4e5n2ZvnPGzEvAMks8i961LMePoi8CDrR8bw2ssRZQSm1XSl2jlOqO4aNvCizzc2zOke6Hb98uWPmL877wYGy6o24CkOpzfj0YRlt6B6nuJq+dYfzf7qCg3Fg3M7ky5JIC/PjayOdcuq4040fRTwY6ikg7EakG9Ae+sBYQkQahfQDXA+OUUtv9HJt7pGkw1tRXnwyE18+AnRscjgnaxa1qM2N9nGfSCzDx+RSKsB/56DMRJlhuTSmSpa6b0hLYuzPBg7Mke6VSqgy4CRgNzAOGK6XmiMggETHj2ToDc0RkPkaEzS1exyb/MpLIluWZnd0YFNMaLN0duy/sukmfOL6Ybo2OcRDOb0PxXv/YbYu+SUikxIkjq59rSXbDmAVx2/sVQ3vCo45Djz5Iz8tZ4KeQUmokMNK27UXL54lAR7/HZjXPHmH8H5LggFNWDcYGnBmbrglTn1ni3Z3OqRS+LJ0VE4hZoWfYJZHf7pcX4tdRWRK5Z2umJ12MtJBp10k2hK46sXVFpiWIiy9Fr6mqZFmum5W/QJNDfMrht3GqAMmP3T6kfpzjMuhe+upWW5Eky5Lya8tUjyHAdWWiESjdA4U1gx+XJeGVVZNPBsLbmQjZz8YJU1mQ30UpYywh5jdxKLtsXIBzBYwoSvq9SKC+PLt9lSWWqaZyPNIi+rvfZy1LwiurJjM/hKU/JrfONb85/yhT30jueZJOFjxwZt32CBOnc75zIZRsj3wvLXGv1ykG3fM67AN6lSTePXPab1f02kfvjyCum1y9BwmSu4o+2SwYZcRH//aud7m0+egDPMhZ4bpxq9tlu1XmR5rDXJdgLadr83O9qR6PCNfvQ9En+75ni+866VSx68qixkYrer+s/Nn4v3N9nIJZ9DCGJ5ake8JUJSJpTPJsfne3HOsqoEWfDf5w+7UlKtOLJ8J/rMsRplqxZNGzDWSfPDayqMHVit4v5rTvmg29y6Xst7VVvKvY/zFZ4SuMZ/kmWq1TI5YFL5jX+Ih98DjRhnjdLCNbY6SixOoJSqYs1VRF3Ux4JvluXr/oxcGTRLLzcsR9yNP0su3wMcHYy32QSlxDJh0L+6tjywojkmbOp9HbiybHHuv5m6d4MNbPi5tq100WuQySi3mfknx93w7JUOCGndT9brmv6J/vmWkJUosfHZGJLuSklwzFHF5aMagMtvJmagFzuTyTr26PPXSXR1K8tLtuMjAYm6z6htSHsU8kpy6/bF4G71wcp1CGDJiE8VDgUY1y6q4n9xX9znXpPV82TZgKu24ysMLUD48YH/ft9K7b93aXlyUZ1mtFZcYwbHLaXTaOUTf21y5Z9z0FFqH5O0J6xnq+fQCWfOe8L9UTpob/Mbn1hUnjmJELua/ok0Wyf5BVk4PFi7vi0Z0N7LpJ4jXGVBXQdZPO+QiJKLCVk6JDQMP4ULaptuhTwfa1RsgykNpBX6+6A7huErmncz8Lfsz67M7oYpKbiv7d32Xw5D4fsNdOg7fOS169jpZtwMHYlJDgpC238ovt1l6iSsdSv1PkjhNbV8KU12HvDni9Hwy/ykHORHz0ySKFv3PUoG8KiXmO/Sj+DPLC8e77iheGPmR+zCQ3UyAsTsHCwH5dBNlonaU76saxnqBRNy4K1J68LajrxnGg2KdF/9Z5RtK79n2M72tnECOnH/eCBHTdKJXeHPBuMkS+pPBEHr9nkOczGwakd7tExlmvI01y5qZF74fta+CbB/z7ZzO9wHYiSjjwMcmU3a8/1a0B8HueoC+KQ8V+V3javTlURagOEffrCpJKN97vNOdTGH6lDwGzQLlVFi/Ft8nWq8hGowqM7Ldblvsra72G5eNh16aUiJR7in7K6/7KfTLQWA3IKTzPkzgvU6YePk8r2kWmPVugvCwVwkQ+xlN4QRsAX6cP6iZyaOxL9/hoAByeBetg7L7d8OTB8c9fvBBmfOC+39eciSSTqUVo7FFVVobZXbJplHHB186rXTkxtGckC64Tbvd23Sx4+/zgsvkg9xT9V7d579+92RhEK9trfN+1wQgjCzJhYt9u7wcyJSQQxud1yLA/wONtYYTlfqXi5U502Te/ERZJcd2UG42e1Qp7pAV8fI3/OpzYssxfuR1r4dM/u+/3fY3JHEz3qitFPYcVPyevrmQ/y+/3N1KgpJr1s1NSbe4p+ng80Q6e7hL5blr0v7wYXc7VpaNg1F3GEmcrJznvj4fjcZUk6LR/M6XAtLcti1kn0UcfE/GTxuiaoLlulIKhx8ZaYXM/dzvY+OfluvEkoKKM8elXkooK+O5BI5LGjWL74jtpsJ73BVylKd29Dq/5GZ4kMGCfZPY/RQ+wbwfhm/3Ts8b/IANk21Yb//fuSOz8r/dL7DhPEnDdmMSzVIqmGL0Yk3lfwQ6f8xPiWfSVdt04hZV6KXoXH32Q+RZhmcW5vphylcSeGwdg9VSHgj4bkKLJxoLkXr2Iz27wV1emeOJgeOkk9/3ZMBibReyfit4J+4PhqizizGTL1ISpQGkHAtSxYx28eip8fqPxvbwMPhwAb54TrO6gVoxf2Z1eaC9FH9bRluMC57Sv8Dh3kn7/eV9FZgM7WfS7tyRetxlOarovnQslXr+db4dEnh8vgty73cWw2zJwuX5u/GPmfmG4afdsjWzbMN//ORMl1RO9fOBL0YvImSKyQEQWi8hgh/31ReRLEZkhInNE5BrLvuUiMktEpovIlGQKn1RiFL3Hj2GWfe9Sh8Hf0HGzP4HvHkqaeI483hYqvAZTXazpCf/2Lg/w4RXwWr/Iosdrp4eKhJTcZi//s4o9d+CoG7/K10nZ+oiiiXLd+Iy6iRzgXE8y+XAAvNTb+OzbdVOJXlDcqisREjjhmfjpvSvLC8fFL2P23osXRbb9t1f846zX/t6lweSKX3mS63Mm7hMkIvnAUIxFv7sAl4lIF1uxG4G5SqkjgD7Av0SkmmV/X6VUd6VUj+SInQLsL5Obotkwj8gkoHL3wd+Pr4HxTyVNPMcHYs8WKAstyuFnsQ2Tbx+ILTL2yejv876EVQ5jCZVRio67fTYA+1zcZAd0D2gxOfV8ErTonVw3ViUYVCG6jQs5LZXoxdaVsHpasGPspKIB8xu1kiiTX41Y647zFwKEvFqxPh8LRyUgmIePXlXA7I8TqDMYfkyFnsBipdRSpdQ+4APgAlsZBdQVEQHqAJuBVMTtJQ/7gxBX0YfK//qS9wuc9m6Zx8MbRJYfHvYuv3UV/KtzHEve4bzJirpxo3lXS+I081gHhellUfqNo7eX9xyMVcY9C4Jbg+PXov/5OeP/lNfglb5+Thhclsrw0dXJqcft9RtxB4y8M/6BqXoWvY7ftclwG9knvu1cbwmGgFRFNPl5gloB1ie2KLTNyvNAZ2ANMAu4Ranwk6KAMSIyVUQGVlLe1BFotmIGpmXHs3yt+395AV462Xmf90ncd1WUGqmRZ7znsyq/UTeVRRmNrxUnxT1/hE0uaxVBLXqzfgeL3qx/5kfwvkM3v2wfzHSJmQ+i6P3og89ugB8edTjWz8FJ+L12FUcv0l7msSRkkHN6FTNnTjtdY3iOQ5zfe8/W6GcoGY3exnnG/4n/jVMwNe+JH0XvkUQlzBnAdOAAoDvwvIjUC+07QSl1FIbr50YR6e14EpGBIjJFRKZs3JhoGFMlsIfSxfy4Prvkybbo9+3y7vJGtachRg02fOpJsVxs2wpq+Kkots5URd0oZbiwora5vJiblzrnqg/6IvvpAbglu5o+zP0YN7eYPdvlluX+8jlNHwZjH/M4X4p7n6NihvMSo7QkdlasG9XreewMvbdbVxjuLSf27oDH28A390e2VVrRK6L0R5YOxhYBB1q+t8aw3K1cA3yiDBYDy4BOAEqpNaH/G4BPMVxBMSilXlZK9VBK9WjatGmwq0gI2822D2q6uW7iseBrmPRywlLF8NZ58Mxh7ucPG8wB/dKJElb0ceq0Wk97tsKwS1wKBm0AHI6PWbHJRWH+50iH2ZXE/taL4uRK8nLdmNddy2UlMrubyUuOSKXRX9fOdC7mRsxEJD/ZH712+nQvuAUKVFQYM4H9NJgi8NkgeM6yZKLX6avVNv57+eg//TP8u5vz8WbIdNSESFtdZXth50bnc+zc4CFc5vCj6CcDHUWkXWiAtT9gX6l5JXAqgIg0Bw4FlopIbRGpG9peG+gHpGbqV7JJdGZg8QL42sNPuG+X93nX/BZ9bsd4aQt+YsaVgjXTvetxq8t+Hwqqx68n6jgF09+LRO34JoBFH7MGayUtdKfGIKr+UPntq3GVs1od5+1evUFXxVfJhvqNs4z8K0HqDXIPvRovJ6a9ZSjbSS/FLwvBZq17uqUS9H/b78VHV8NTHZzv0a8ORl4iGU6TTFxFr5QqA24CRgPzgOFKqTkiMkhEBoWKPQQcLyKzgO+Au5RSxUBzYIKIzAB+BUYopRIZtk4+cePSPR70ykzGGPMP933zRxiTl7y693acXDfhfZZtL58cvy7PUE1bnarCfVKNfTDWM649GRa9j4ipBSM9qkhwMBZgli1iwpQ7kVTEvpVrAopiu6UTHvT53bPV/ZyrJsNDTWDJD/7rM7M6umV3tBPE1WFNOGfHz3UPPdahTtvvYj5LTg1zXPdnvGtJzWCsr6dRKTUSGGnb9qLl8xoMa91+3FLgiErKmBlSlevDOsnDjhnfu2KiMWhz6Ts+5PHwgYcVt88XpXxf/DJWpTh9GFzoY3Ap6ExVz+32Yir2BfaVkdQW4hYE6z1Y4xLGmF8YrE4vOZIx4cYpvYBfd98bZ8GZjzrvWzHB+L/0BzjYHukTJLe8mxhBr7WS7+3eAGM4FQF6MuYzunJiRnz0uZmPPil4/Bipml5t1jvvS+OB++nfkX1milw7Xha9qej9Plh+uuC+s11aG6AEHuwg1q3fORBuWC0zP41EVESGy7XluSh6z4F8h3OX7Ys/XuTU2NnZa1X0fnz0lnNumJucxbPXhcYWXNv2FCvAIO+tU4iwHc+ZxS51Acz/yquwvzoDolMgWLH6MVO1PqabwgZLt9P2HeCT672P8bLo93ic04ofRe/HvRNFgq4bv5SW+B+MdZXBIp+fY/2E3vkdWI13zL6dzj7iqON83MPA9yRFPdqU1GPB631I1EBz+y399ICdsEeJpYH9WNE7PAgvW7qeyfLRT30z8rl4sbG4QFyCPJAecepBB8kcH1y79egzvYD1hUvIdeOT8U/FDsYunxCsjihF7yfzpfUeuMhvZge1k8hgbNzolABurhkfWFbpSmKkll2xfjAA5nwS76Bg5/AniMe+RBW9PbIq9Lz5tegDXWcGffQ5iVP0S6llW7ISEX15C7Q5AZp0hE2LnctsWw11mhN+IAKtTlThLl8QH6JbeXu9QWeRxrPok5EPqFaT6O8Tnw92vFU+P9fnx3WTCE73SSR+46MqAB9pElZONKJdmtkzmNjYtSk6H0wieLon0oCfwVhrcjNPbL9xXgGUl/u36BX4noeTIvYvi96cHQmwZYV32Smvub/0Qdfv9Hogdm2CZ7rAN/dZNibiS3Sy6AO6WfxY9E6um1H3OCzaHWL1NG9lOD0Jya7K/VpW1mMs1xqluF1+c2sseuB8P1YCum7i9ojw39iYxo2ZZtuNoceQKl9xFKV7bBuScE7zXuzZEn8h+a/v8lmn7f7neVn0Ltfwxpn+zpUi9i9FP/oeyxcnH57ldox70oj/Du+rTCvsceyu0ASLJd97y+ZGMi16J1eP/SF3UvS/DIV3L7YeRPgaPr4m9T5J311oCzvWRz77seitOX4qY9F7Dsa6hOvFa1h8jSdJZLau0zPzywuR3DxekWFgu4ZKpGr+JV7ElqsAHvtC596+2ngmS7ZbDrMd53ehkxhFH3KEJOq6ydKZsfsP9tjnvdudyyWK00tuPiwb50dbI75Jpo/eh+smaJ2QmCJOdf1uA7AbvfKTh34/6xKDgQftg1r0FT7O4UNxrPnNkrXU9sxsX2ukK3jvDz5DU+OcO5FAhuUTPFZwsp/D43pjnldrLzWAsea1XoGpFxLpSWaI/cNHP/LvsWsxOo7Ke/g5K9MKe1lx1gcxJmdLgHM4yRc0KsCpfIxFb1P0o+6OL0uqfZJxk2U5YZHxZ4tPf+JQf8ckiudgbEX0fwgp+jjn9fNsWvMlufXSSrbBjw5J0OyU7YXnjoaznohss44/xY3McpA38EI2PrH2voKsOeGnXKLhlRlg/7Dof30JVvwUvc3J6khkNmNlsT4slVKIDg+TUwIvv7KEq7XdJ2sUETh3vyvKoh/uVD/oCSl6C9YImcA9lqDX5sOit/c24g0Q+7Ggrc9WjCI2r0Gix7Hc2LrSUOxf/53w9VhnHgcOwU0mHlFigTLUWoslObwyA+wfit4JJ7+nPUtgOrB2/yoTu+/0zAb1jYfD7uJVHIdvh0R/T/WLn0zX0MKvA5a3Z/SIc7+8cv44KvokuW6sDYzZcDj1vJKxEHmyf+9APVt7b8X6nidq0bvNjA04eTCD7L+K3gm3h/y9S+G3d5z3+avYfZc1MibGPxroCY9d6KJka4DjcQ45TaTxsfeeUq7oE7DoUzUhzkt5zPvKWAXJ9VhTAQdU9LuKHSJYYiqPPY/1HCa+jB1LD8CJwCG4Hjj2cj3eJ3Od3bAslh5aTF1+3y+Xcn7GtMAY+8gw+4eP3i9uij6h5cMccIpN3mTZFpMqOYCiXzcLvjoVznrSGGtQ5cb0+SA4KYtE3C72tAfZaNEnpOgruWDHpjix6U4WfUV5/Kib/3SHA47yLuP1O4aNDQnmvnRzNabcdRPgmYwKMbZb9HGegfIyI3qn0ha9DR1Hn6uEHswx98busmaztL/Qfldzgkge7RnvR17WoFEBToooEYXo2X1OAamO6gFjkNYp4ZUdz3zzcRRURYIWPbgnV4tU5L7NVFhC8PVprYy+1+iVpvr3DjL25GXRx/s9vn0Anj3ciEpyIlEf/YKA7sEksJ9Z9OlvSQH/VnFlXhDrQ5yXD+UEt+ijFlsIkZBFb1NMC13SASSLyg7G+mGDy4pRdjznLsSLnnGw6BeOij/ByQ+OSyjaFD3EppNwwuz5FS+ExZZFWiY+D21PgtrpWDjIJ1ENr31mbJwcUObcluKFzvsTteit9yxN5Jai98r1DvEVqX2iyMwPoauPJdvi4dcqrswoftTLGvpZgw4sOpGQi0NFK5Z9OyovhxfpsOiTQbxG85W+0Osv0MeyBF/UJL9Kndx9V5TV60PRW1NM2HM3Oa2TGyNKGgcnre+F3aKPt6iP6cr96lbn/YnMKckQueW6+fk57/1BLb+1M+BfhyYuj4lfZRlkwRE71kbMj1Xml2S4blKNmf426/Gh4Ca94GNgNZFTeyl6y2LnmYg882L1VH8uMzfKSysxzhQv9XOKDZgkkmW/aorZlaH1HNOh+KIUfRI7aol0M1VFegecdrj4ULMNv/pm1kcpOLfTM2j30QccjK0KjH8K/tkA9u0O9h7uXAfrZ3mXCc80TiIpem/2L0WfKdKi6B1cN8lgwtPBj/Ezm3O/xO9YTSpcAl5RN5bz5ZqiNw2VVb94LyeZ42hFnw7WzoDne6b2HFarLBuUbEZnR2YpvgflU2AY+BmM3bI8OROmvJjksHh2Olg4Jk0nquS7l6J319evKiJnisgCEVksIoMd9tcXkS9FZIaIzBGRa/weu1/w1a1QvCBusUphVazp9pE7kgWNTdbhV9GnoJFc+oP7eaxuv2TNGXHj1wwp+kkvZOa8WUJcRS8i+cBQ4CygC3CZiNhXLrgRmKuUOgLoA/xLRKr5PDaztDg80xIkB/OlXTc7+IxYTXrwa62la6k5M8ornb2vrDBC9j/8WPQ9gcVKqaVKqX3AB8AFtjIKqCsiAtQBNgNlPo/NLNkU8xuE2s2iv5vJxcr3VqlkS4FwW3C7yuBT0f/6UmrFMDHnWcwanp7zgZEQbcrr6TtfulkXZwA3HhkcjG0FWJOoFIW2WXke6AysAWYBtyilKnweC4CIDBSRKSIyZeNGt7zUKSCZoYjppOefMi1B+qmqvxUYyx1mmzVbvhfeudh5olyqqCg1IlpylQxMhvKDH0Xv1MTYTZMzgOnAAUB34HkRqefzWGOjUi8rpXoopXo0bZpGK1vy4RiL0hyQxodeE4x4A4XtTk6PHImwuxh+eTHTUkSzayMscVkCUpNT+FH0RcCBlu+tMSx3K9cAnyiDxcAyoJPPY5NDoqPVkhedY6agunvZ+gcldo6UkKF0DpkkXuhf5/PSI0eipHqGsKbqk8Gom8lARxFpJyLVgP7AF7YyK4FTAUSkOXAosNTnscnBybfVfUD84/Lyon2GXsqkvqPXKXXUaOC8vf/77JdRLfEs+mwIK7XS5oRMS6DRAD4UvVKqDLgJGA3MA4YrpeaIyCARGRQq9hBwvIjMAr4D7lJKFbsdm4oLieGwi+G8Z2O3X/pu9Hd7bo98jwG/dE8mOd+S0qFBm8jnjv2yz9+bDuL56LPtnjQ+ONMSaKocGYyjV0qNVEodopQ6WCn1SGjbi0qpF0Of1yil+imluimluiql3vU6NmWcer/x/6ir4JLXDaXd5UJjW6+/wE1TDSVpxa48vJR5vAide5LslWppCf1s1jnyOS8/MaXWtFPlZcokcSfzZJlFn64xg5bdoV6ae5uaKkVuzYw96Q4Yss2whE1XzoUvwF3L4azHoEmHSIheQU3jf2Gt6DpqNogOXWzfN/I9nqKsVruyVxCh11+irXhrAySSWErjGvWDZeNs4jOhW4tuUOhx7S26xW67b1PstnjEy6yYSOP392XBj/FLt0tSV7eVpp0M40ajcSG3FL0T1WpBzYaR73l5xst913KjYej3MOGBzWNvgIZt4YZfjIlUN02Fqz6DwlCj0Ob4SD1mT8Hk7KeM/1d8EqozRMcz4OoR8JeJxveznow+TvKMc57/fPRgb7XakcaqTouIojePL6zhfs1X/A963xm7/ZLXI5Nj7NbmJQ6xzV7nMN1ikgeDJkR6H6c6JHrKK4D8atHb8l16Tp3Pg07nOu+LlwMmiI/+qi+gw2nGOIifsZygHHBk8ut0I69Ap5zQeJJjGYx8UquR8d909dwy3ZhR2jmkYGo3hkGWPNsdToMpr0HTQ40eAxjZ8NqdBCXb4bt/QvPDQmVPNf4OvxRqNopWaLfPh7otDCW+bhbMHwG3WSZYHP4HeDjUezj+JuP/VZ8blvXmpTD3s4iMx90M3z8Mpz8E39wXfX0dToODTzUU2NQ34KdnjRDS+q0jyvCoq2DZ2MgxDdoYDUrZHqhWF7YXwaHnxK7BaXLklfDlLZEGyGwMnaz30hK4dz3M/hg+iRf/L9D/XRhSP/LddMmYy8I1OcR5MYggFn37k40/gLMe904RXac57Fzvv25TxnSRl68VfbbS4zpDd5jUPxC2haYW9RoEk9ITcpv7Fr0fGraNKFAnznocbp4GdSwunWq14Jjr4cTbYODYaGsfjLJ2q7VeS8NKP3KA4UqyKnkwQjsveQPuWBDphbTvYxzX9gSjkal3gLG9sIbx/YS/wi0z4frv4Oir4cTbjf0i0KhdZFzBHIs47KKQLAdEn7tRe7h9ntHbuX2O8dmpVwDQ41qjvtMfMs4LERdY6R7DZwxw8SvG/707jJ5Uq6ON78f/1fjf+Xzjf8+Bxm8ARmy3lfuKI5+7hMInm1myaNRpEfncvo+zvOH9fZ23m+48tzGAM/7Pu97TH4zddu4zxn/zGuNxxqP+yjlRuju+Ky+RCKBDz05MniD87rX4Zdww3a92ul4Cl6dxtq/Xb1yneeRzy+5G796kVpPY8ifdkTSxrGhF74f8QvcIChE4oHvyztX1YsPqD0LDNtC6h+FOOc3mOmnYzvhvvrRdLzaUeJvj4U8/GC/akG1GLycvL9Ig1DvA+P6Hd6IV2WlDIkrshL9GXDam+6NFVzj1Pjj4FDj0LDjoeLhwqLGv8cHGufo9ZHy/5A24uwjOfhJumgJHXAbn/MvYd9IdhjvL2lj2e9joZZx6v7FkXbMukRen0cGGLPdtMuS7eRr0sa3OdEpoBbLbbIFfBdWNXtDlHxmDmnVbGvWf+wwMXhX57Z3yIv1tEZxwS6yrxhyvufSdyMtbrS5c/z3c4tBLMhu6RJA8b0V//M1wzchIb9QPV3wSG6F2wi2JyQfG/XTCaRzDb6N3r8s6BBe+AIecEbvd3nA1Oyz+OawTKKvVid1/7Wjv99+6kEvH04131UQEjr4munwq3IhoRZ/7dDrH6CG0t/jkTWu+1VHxBwy7nG+84Pdtgge2Gj0Yx/OcbSiSRu0NpXnlp1C9Llz7tbulnV9glAGjMb3oxYgL7NT74agrjc997zV6TTUbwmXvGYr36q/ghomRF8lUrPkFRo+j8cGx1lHrHoaM9VtHbxcxxjU6nga3z4U75hv197gWatSLDIofeWXkmLotjf9mLverRxr3+Zjrodvvo+s/4VbDdXbHfGh9tKHUb5oSXeZgl96GleNvjnzucJrxv9dfDMXY3CVXYJcLo8eMelwb+dzn7tjyjTsYDXCHU41G3+yxARz1R+dz3FdsNKxu3L3aeB7csOYwansSHHdD9H6rzFZEDEPCjluIdIvD4RSLm7PlEe4ymVgb8IE/QlNL9Nv138NBx0ZciibV60UCGawNsH3pwbx8OOfp6PGx6vXiy5QA+6ePfn9CJHgPwQm3wdN0cPLf3fc1bGcMANuVKxgyXzvG8OfXdugm+6VWo4g1nBcaPP/1VWNlK7MHVK2W8Wf2SKzUqAfnPBW9rUlHqNU4sk5xYc3IOczxieu+Mc7RtLPRkNVtEVku8wpbqo7uAwzFtXqqMXZicsRl0eXOfSYyQbDnQPjRYj2f/3ykcTVp3cNoKJSKHVA3MXu8F75oyDncUscNv0B1myV81FXGGIbZyA/80Vio+63zIobE3avh0VDI6DlPR2S+aQo8f4zRIAFc8bHxfXtoAfXaTd0Tg1WURlysBx0HbU+EGe9F9nc6F+Z/ZXy+7EOjh1i7MdRrbYxZNelonO+ZkDHSOuSKtActnDYEpofqtY6dmFll255krLUr+cbzZO1p1ElN+het6DVVGxE46Xb3/Qf1Mv6SxTHXG/8P7AVFUyrXiN6xAL57ECbZslXWagwdTocDHRarufRdWDExdruIMRDeoltE0d+73jly6oZJhtIzG7C9Owxr0wxSsGPtSQwca6QMeeUU47vV1dDd1qi4uYqsEwHBcPfZy1evYyjbkq3GtV31hTHu1aSj0YMwlXm12nDjJFj8HWxabDRebpxwixFifPlww7W4aXH0/pPvMhZmr9koehb8oPGRsaP6rY0Gwbqub69B8E0osGPwKqNhNxW9de7Nvt2R8svHR8aszAa0773uslcSUdk2bRzo0aOHmjJlSvyCGo0mlmnvGArJjzsoUYbUN8YG7l0PBdVi9x1yFlz+QfT2ya8ZlrcZ7ZZqXj0din6Fu1YYvQenmdWblxmNdUVZpIeRCOVlRq/EDNhY8DW8398494a5RoTd8TdHDINdxZXrZTogIlOVUj0c92lFr9FoArNnCxTUiITVWtm1yVCa9gYg3VSUGyG3XmlNcggvRa9dNxqNJjjWSYh2ajdOnxxe5OUDVXgNgySio240Go0mx9GKXqPRaHIcreg1Go0mx9GKXqPRaHIcreg1Go0mx9GKXqPRaHIcrehD/Ly4mLaDR7B66574hTUaF4p37qXt4BF8Pcsl4ZZGkwF8KXoROVNEFojIYhEZ7LD/ThGZHvqbLSLlItIotG+5iMwK7cvaWVDvTzZyRE9ZvjnDkqSX9dtLmFUUIKuhxpMF63YA8PbEFRmWRKOJEFfRi0g+MBQ4C+gCXCYiUanylFJPKqW6K6W6A3cDY5VSVo3ZN7TfcdaWJr2UVyhOf3oso+eso/cTP3De8xMyLVLO4JJOS6PJKH4s+p7AYqXUUqXUPuAD4AKP8pcB7ydDOE1q2L6nlEUbdnLX/2aytyyBdVY9OPPf4+h836ik1lkVUdm2ULlmv8aPom8FrLJ8Lwpti0FEagFnAtYcqgoYIyJTRcQjtZwmF5i/bgd7ShNYuDxX0Ca9Jgvxo+idHl03c+U84Ceb2+YEpdRRGK6fG0Wkt+NJRAaKyBQRmbJx40anIglTUlrO4g07k1qnnadGL6Dt4BGUV2S/JZf9ElZ9sjBXoGY/xo+iLwIOtHxvDaxxKdsfm9tGKbUm9H8D8CmGKygGpdTLSqkeSqkeTZsmN/n+HcNncNrTY9m1N3ULKL88fikApeXJdYUkk8+nr2br7n3h79r4TD4Suqtaz2uyCT+KfjLQUUTaiUg1DGX+hb2QiNQHTgY+t2yrLSJ1zc9AP2B2MgQPwoTFxgLT+zz80ZVN15wX0prZatGv2rybWz6Yzs3v/5ZpUZLGjpJS2g4ewcdTizItikaT1cRV9EqpMuAmYDQwDxiulJojIoNEZJCl6EXAGKXULsu25sAEEZkB/AqMUEqlfaTOVOJ5bkuMWRAfZews3rCDklKjESnLAkU/buFG2g4ewaade8PbSkJ+8zVb91S6UQNYu21PxkNR124rAeDFsUsyKoeV8OOT+cdAownjKx+9UmokMNK27UXb9zeBN23blgI+VuBNPovW76Bdk9oU5Oel3F/62oTl4c/ZYNG/EnIjzV6znZMPiXWDJUPE4x79HoDlj51T+coSJD/UjcqGe26Sje6wktJy7v98Nn8741Ca1XVYWlCT8+TkzNjlxbs4/ZlxPDl6QdT2CpvGX7V5N2u27mHIF3MYv8hw7/z1/d8CuwKsnYCyLPXRm1cuIkmx6LOBgixU9CbZFF759ey1DJ9SxCMj5mValECs3baHHSWlmRYjJ8gpRb9nXznrtpWwMeSymLJiCxBRco99PT9KyZ30xA8c/9j3vPnzcrbtiTxQb/28nA07Sli5yVjMd2+Zd7ig1YrLBteNiZt1mUUiAjBs0goOHzI6cANkuuKySdEn4vpLF6mQrKS0nO0pUsbHPfo95z6nJ/Mlg5xS9Fe9PoljH/0u/D3sLg0pkA+nrAr7db0oq1D0fOQ7ej/5A1NXbOHQf4xi/CL3kE/ru33602OZEOodpIo+T/7Ag1/ODXSMtTdj79lkmns/nc32krKEFXYqFP2WXftoO3gEPy9O7LfMpltsyvLZ9DVJjzw7+9nxHD5kTFLrtLIiZGxpKkdOKfrJy0MWvO0ls371oxQqLGUmhwYcx1uU9/rtJbQdPCKs0MViK+3aV87gT2ayccfeqF4CwIiZa12TXf26bLPvWP/lm3bz+k/LXPc7KZmychWS1Z+iLyktT1uCN9PXXloeTDual5GKXtT0oq0AvDRuaaDjstigB2BqqJebLJYW74pfSJNxckrRm5h+cvOls+o1Uyls2+3e3Vywfkf48+ZdRty51RKaEmpQhk1aEXUeExE45pFvOeGx76O23/jeNP4ybFrUtq2791FSWs4fXprIaU+PjXdpgYgaO7AoQz/W5o3DpsXIH4SS0nJ2eliPO/eW8c4vK1BKkR8StLQienzjnk9nccwj37rWYTZY5RXZNy6SRQZ9VvUuNJnBV9RNVePyVycBhqWtlIqakm8qhTs/nuGrrpdDFt2wSSt55KJuAJSF6ijId24nTd+xqejKyitY5GKtd3/wGw5tXjf8vXjnXgTYsruUDs3q+JLRyuqte8LzBqxYlaGpIK3+ZKVU1Pfv5m8wylYo8vKCm6kXDv2J+et2hKNyLhj6E20a1eLZ/t35ZNpqJi3bxPApRRzYsCZ5eUA5lNrmObw3aaXnOSKKPgWaLMEq7e7CbCB7JNFkipxU9FbsETSme2Dd9vi+eie+nbueWz6YDkSiPuxq0O5XfHL0Ak8XgLUHUVpewTn/mcDmXfsSCl10s8LN6160YSfv/7oqZn+FgnwHfV6uFHkew3iLN+ygQ7O6Mdvnh9L1mg3FjFVbmbFqKxcd1Yo7Poo0slt276MgLw+o8HTd/LS4mElLN3F7v0OjZIbUDsYGdcVko+smmxodTWbISdeNya/LN/PlzGif+JKNO1m1ebfnLFkvPpoaUZKmot+9zzsq57eVW6O+L96wg9OfHsuWXfscy2+2bb/khZ/DbiIrL4+Lnijk9UKXWZSo0wQjN799PCV6wfM/0XbwCNa5DHKX2CKWttvGLfaWVoRnFXuljxjw6iT+8/3i8PdVm3eHe1ZeIj729XwOvmeke4E4JKojgxz28dQihk+JbXxTQSpV/uINO8KRalWRl8Yuoe3gESlJY7Jp596kj48EIacVPRizRK3c9N5vnP3s+IQUfdvBIxg9Z334e0G+sG5bCR95xN3v2ltGsWWGKsB/f1jCog07w+6ReExZsYV7PzUyR1iV+f+NnB9Vzm4RC8Kz3y7ip8XFMf5vO24KPd7A7a5QIzd3rfPiJWUVih8XuF9nWYUKu8CWb9rFGc+MY0Oc3tbKTbs56YkfeOabhUB0zPquvdHROy+OXeLZWH03bz2vjnfobYUan7ELNwZ6Vuy3662fl9N28AjP+RV/+2gGf/94pu9zBCVd9vxpT4+j95M/pOlsyef5kCGRiuyrv39xIr974eek1+uXnFf0TuzYW5aUaIGxCzZGhXM6ceHQn2LPFVIiiTxQXtarPd5fBJ75diEDXp3E3tJYRWNtNNwGgk0luXNvGRUVih0lpXw3b71jWcfjyxUPfRUJBTUbLJM9+8rDYxqvTVjGgvU7+Hia94S1tduMaKCfF28KXYexfcTMtRz2wGge/HKOb/mue2sKDztNJLLc52/mGtdbXqHiukHM36ektII3floWnrTX4d6vfcvkxuZd+1i8YUf8gnYsImfCjbNtt5GT6LPfVqf93IEwgzcC2oATl2xiyUbviLlMRyftl4o+WazxEZPvNAhrKrb7PovN72Z9D51inu3dylOe+pHZq7cxd832GMvTasnGm/RVtMU5lLKiwlDyXR8YzROjF3D78Blc95b/FSHtoY/2SJzd+8rDrhvTvfTEqOgZzXbKzZtkvpih7Te+Z0Q0JTvJmQhs21PKwfeMDKeXcMNUpPPWbuefX871jDwKSr9nxnLa0+Nitu/cW5Z1fvjD7h/Ff75bBMCSYuMdePPn5WmXY0dJaTjPUzzCE/AC3svLXvmFU/+V3Ii5ZKMVfQbwCmKxKufDHhgdFdO/bXdpjOJcWryLc5+bwNn/GR+zWpQ1Lt/Pwz55+WY63jsyKhlauVLh+QCfT1/tarns2uscTnnMI9+yz8NtsXtfWSQM1oeToaJCYXqhdpSUmQdGy+IwZnLmv2MVpF/yhPB4yrC4kUAJn4bpq7aGP09dsYW2g0cwe3XEJVa8M3ZMZ922Ero+MJpXx3vMq/BxX5VSPPzVXOat3R7etmj9DkbMTGyR8137ynk65Foze5PVC9KvbroNGeM7bDlo7qS12/YEDgSoSGHggBc5pejzEwgDzAReg7d2n/h/vl8U/nzEg2Po5/HQ2i36By0ukz1xBowBXhm3lNJyFZ4kBtEP/dptJSzd6NwFvfn93+j6wGjHfVs95ix8NXMt67cbDYufcPhypZizJvhi5mYUkElJaTnPW+6tFyJCQSgkyR4CaidIjpuS0nJ+sIxfXDj0J+4YbkQkme6xsQu9F+Ep2mIMfn4921DIZeUVMYP5XoyYuZZte0rZuruUVycs4/JXfgnvO/2ZceFeUmUwe5PVC/N555cVjF+0kSUbd/q2tCuLW2/Vjqk9ynw8iGu37eG4R7/n6W+8e592gvYWkkVOKfq+hzbLtAi++MrDSrJHr/z722hl5OUu6vPUj47bqxfkUeJjQPEnM2+/ZVD38VHz2bOvku4Hj2fbOvt24tJNkUMsL0TbwSPCn8srFI9+HT0I7VuMUJ1KKV4Zt5SnxiwM75u8fDM9H/mW856bEOMG+fM7U8OT5HbtK6fd3SMYPtmIknnhxyW8+0skIsrrPVZKRQ3KPvjVXK55Y3JUmf/Zxie8XDIPfTWXS16cCETcDg+PmMdRD33Dbstvdtf/ZkXqsxy/vHgXN743jTuGTw8fn+gsY6tL0W7lmj3N6gV53PfZbK587VdO/ddYbh8+PaFzxePyV37hX2OCKeCflxSzKdRAlvmYob0hZJyMD5juJFPpR3JK0WebnzIRLn35l/iFAlK/ZqGj9WRPwGW6PKxW68dTi3jOEtaYCIlYMe1dQiKt7g0TheLuT+JHrZhRSe3uHsm/vlkYte/3L05kw469zFq9jTlrtscce+uH0wHDV68U/P1/xvkeHzWff1jGWrwu9YnRC+g2ZExYKXqlvPATj//ahIi7xixvGhGmGy3mnbCOAYUag6Ite8I9kURdCx0tg832cSTz2bO7bkbOWsedH82IahieGDXfNVfUkC/mcMpTP3q+5wvX7+DnJZsCP7OXvzIp/DmIO8br9y6vUDw9ZkHULPxMTeLOKUXvN1wxHo1qV0tKPdlCg1qF4YVRrLh18e3bV22uXGx0vHkGTri9QBt27I3ZVlquYiaBObmqzBxF8ahM7hwv180LPy5hT2k5He/9mhd+XOJLqZr3wZ43yY6Z58mcrF1Wrpi4ZBNv/LTc9Zib3vsNMHoD4clnSTCW7O69iEWfH1P2o6lFLLJEEv33xyVc8dqkmHJgDOYuLd7FE6NjrfWKCsUz3yxkWRKiW/y4bvyMK30zdx3/+X4xD4+IuFC16yZLaFCrkLev7cmfe7fPtChJo0GtaoH8oY+MjA43nGab8JVJ5jpY2050vn8U623x+Ct9Nlh5QrgbH5SZRf7GD54cPd/1pVdKsXC9Ye2bJc59bnxUGbff05hlbFjVl73yS9Q4jf14Uynm5UWsWCcd13bwCE5/eiyj56zzvCaTs/8TLWtY0Rd6pwyxYo5VOGHtyZj8tmoLz363iL8mYanMsgrFxh17PUMmxUfSZ/O6rUESmUqpvd8r+iHndYn63qtdI7q2qs/dZ3fOkETJ59dlm/k2QOx7NhNk2cAFtgHY+z73t1zxCz8u4W8fuSsaJ659czKTlm6KWezGjQrl7gv+eGpROHYfDKW8anNkLKOiwrDW7UxdsZk1oTkG9ggsO89+Fxn7MSz6UN4gl8Zn0Yad/PmdqQz+X/CJXXtDjdL8tc6NtFMMhX2swoo16ODGYdMYNXtduOcT77r9UFauOOHx732FTHoZ6JGcUtbyWtEnjYEu1vjpXZrz7e29w9+n/uM0rj6hXVSZJ39/hK9znN2tReICZgC/kQe5xNsTo9NGuEUM2fl6tj/L9X5Lw/H9/A2BI1RmrXa2/meEUiSD4Ue3N27lSsXMtgb43QsTw4rHzeIfv6iYIV/MiertCBFLs7xCsax4l+tM3g8mB0/VYCpft55hvFXPvp273tF19eZPyxgxay2D3p3quODLcIusu10CClZt3h2zilVZhYo7G9o8ndN4jol5SdYei92in716W1qij3wpehE5U0QWiMhiERnssP9OEZke+pstIuUi0sjPsangnrM706BWIQB/PbUjD15wGADnHt4yKgFXg1rRvvivbzmJejUKw9+PadvQ9Rz25/KiI1u5lv36lpNY9ujZjvv+cU7njK67msukuhdjb0ic4twTwapkXhq7NCbyavOufdwZJ2WCm2X7+k/LePPn5VEKZ0bRNn4fit4BGPDKL74sYz9jN9NWbglb9G48//1iTnz8By59aaLj/uvfnhLjkvlu3nqGWBbfucMhgufvlt6HefyU5Zt5fcIyXhq7hOmrtnLSEz9w4dCfoo5LRtrrMXPWhRc5srZB1h5TSWk55z43gT+97X8CYqLEzV4pIvnAUOB0oAiYLCJfKKXCd1kp9STwZKj8ecBtSqnNfo5NJj8PPiV8U3+773QWrt/JoS3qopTikOZ16dWuUVR5M+7+t/tORxE7CPvhwOMQMcL+lmzYyX2fR6bWDzn/MBrUqsZ1J7ajIlT/PWd3dsyf3rllPVeZq0rsfyo47IB6nhbR/opX7iSAXv/nnXYDiFLcTnw+fU3Ud2uY65ptJZ6KfnnxLgZ/MpNflm52LWNy8X9/5sa+B3uW+TSUGsFroRv7IKt9dvbyOMnUJi/fwufTV4czz1pZYuvpWV1qJaXl1Cg0BpGvev1X8gTevKan57nKyisY+M5UR9mtbYgZMBA0RDMR/KQp7gksVkotBRCRD4ALADdlfRnwfoLHVooDGtQMfxYRDm1RN/z52PaNw/tG3XoSy4sjD0ZDlygbMw/78Qc34fiDm9CpZb3wC9S8Xg0evbhbVPmmdatTt0YBJ3VswrP9j4wKOQOjIWpYqxo1q+Vz76ezGDZpZTgDpl8evrArq7fuYfScdTSpXZ1fl8d/2bKV5vVqaEXvQDZECU/zyLT4zy/n+FLyJkN/8D+u4sYmB1dVELbtKXVU8k5Yo6463Tcq3OO2J0h0IzxjO4Q1e63VoreGoS7esIOiLXvok6K5QH4UfSvA6pgrAno5FRSRWsCZwE0JHDsQGAhw0EEH+RArcTq1qEenFu5WthvHtG0Ut8ysIWeEP0+//3TqVI/cYmtD1DjUuNjdR1aWP3YOl740kUnLIi/VFce2AeCuMzsB+AoXNFnyf2czYtZaX5EJ1QvykjKw5YVTtIUmO7jew51QLQOpDJzSWqQKe8SP18JBTnjlNzJDapVSfDsvEg5u5jBKlRvXzy/m9Da62RznAT8ppUzN5PtYpdTLSqkeSqkeTZs29SFW9tOgVjXXVahuPKUDT1xyOOce3jJq+6hbT+Kf5x/G5zeeAMCHfz6Ou88ylPo/zz/M9VzDro9uPwvzhZtP6RD+/vKVR5OfJ5x/xAHhbXMfNBqlS45uHVNfzWrRMc/vXteLf5wTiURq37S2qyx+cbo1Xm4uTXZgTdWdi9gXJXpyzALOejY6ZHSRQxbRT38zXG7bS9znPJiROB9OXsU9n85yLZds/Fj0RcCBlu+tgTUuZfsTcdsEPbZK8NKVRzuGtgWlekE+f+gRuTWnd2nOL0s2OfY2/nRSe07p1IyOliUH7ZzQoUn484z7+1E/NBhtzhDsd1gkSmjIeV2Yt3YHtaoVhC2IMw5rETUodMLBTWjbpFa4231AgxpRD/cTvzs8PP0e4KiDGgSOt3ey6P3a+B8POo5WDWty3KOJr2tr55ROzfg+SZPuNLnDJJubyq0XfduHM9i5t9wxK63JvLU7WLV5Dz8nQYcEwY+inwx0FJF2wGoMZX65vZCI1AdOBq4IemxV4ozDWnDGYckPrXzlqh6u+/LyxFPJHxyyro8/uDFtGtcKK3mASfecGjPT0x5SCkZDM/7vfVm8YScrN+/mwiNbUb9mYVjRN6xVLRypce0J7ejRthHDru/FgND6vAc0qBmj6N+85hj+8dnsqNDO1/7Yg+vemsKlPQ6kVcOaMaGMfTs1Za4l3vqq49rQuHZ16tQoYMWmXeFIlx4hN1qNwjzHWb9BKcwXzjuipaeir1ejgO0lyUs7rKkaBHFheil5gEHvTvXcnyrium6UUmUYPvfRwDxguFJqjogMEpFBlqIXAWOUUrviHZvMC9jfmffgmYy85SQA3vvTsTx68eFR+5vXq0Ery9iAFwc2qkXfTs344/FtqV/TaCy+vOlErj2hHQ1qFXJIqLHpflADIDrH/Q19OnBA/Rph99L/XdSNPoc2iwpXBTi1c3OWP3YOj19yODf27RCT0+WQ5nVZ/tg5HN66PgAPXtCVW07ryHUntuOC7kYIa09L9NTEwacChMs70aBWoes+k/w84ZxuB3iWMcdHNPsX81wmeqWCB79MSZyKv8XBlVIjgZG2bS/avr8JvOnnWE3ysPvSk0231vXpFlKivQ9pytg7+9CmsdGDMCep/P7o1nQ5oB4/320o3XMPb0njOtUBOLVzM+au3c7TfziC846IVqT5ecIxbRvxq2Ww2Qw5+3jQ8TE5R45u05D/DjiKUzpFIhMa1q7G/IfORCkj7YHJBwOPZeKSTbRvWpvSchV3pmvbxrWpVpDHEa3rM6NoGxcf1Ypv5qxnx94yurWqz9DLj+KgxrVYvXUPn09fQ8dmdVi0YSc39j3Yd1TJs/27+478qJaf55nH343uBzZwTPymqRq8/tMy7rfN1k8GvhS9RmNiKnmAkzs25e6zOnF5r+goKVPJgzFhrVm9Gpx7+AEUOoy+1qsR/QiaVnu1gjyqOXQ4z+7WMmabGec84a6+nPi4sWZpkzrVuO30QwAj0mH99hIqKlRU1srTOjfjxA5NaFK3Or3aGeG3n914Ah9OXsWFR7bir6d0pM9TP9L7kCYc1LiWcW21jWu75OjWFObnMeDYg+Iq+hM7NGHC4mJO79I8vO2+c7twYMOaUfHWJg9f2JVHR84jSKDJrad1pF2T2pzTrSXjFxVzzZuTHcstePhMDv3HKMd9mtxFK3pNwuTlCX8+2XsyTGF+Hld6uDz6HNqMb+dt4M1rjqF3x6bhuQuJ0LphrfBnUyGbct7Y14hAuvK4NhTm5/Hh5FVc1vOgmB6RiNC/p9FwtW1Sm+/vOJm2lsbNDC0sV4o/nxg91jFzSD9+99+fWbRhJ/84p3N4LdqnLz2C8gpFrWqR161fl+Yc2KgWn9xwPBKSt1wp2jUxzvXJtCLHwe0OzerEpDdu1aAmt552SPh7307N+HjQcVGD5SZOGSS/uvlEzn1uQsz2VHDJ0a058qAGMWsHZyOtG9bMmdQhOZnrRlN1GNDrIMb/vS99Dm1WKSVv8t8BR/HmNce4ToJrUKsatasXcO2J7Xy5vdo3rRMlV6/2xvjA4a0axJStV6OQ/91wPN/e3pvrT2ofzr9er0YhLesb4yRHhsY3aofmVxx1UEOOPKghBzWuFVbyAK9ffUxM/Qc3rc0rV/Xg72ceGrW99yGx4cheg/cfDTouKh+UfUb4Ic3ruB4bj5M6NvHc37NdIwb0im34rzou+8Y/+nWpWvmsvNAWvSajiAgHNqoVv6BPnFw7yaTvoc2Ydt/pUcpx7J19WBGagl+vRmF4AHr4n4/jyxlrohbcePe6Xvy6bHPcNQ8a1KrG61f34JER87jn7M40rVudw1s3AIyB72PaNuLnxZs48qAGUYPTJtZz1q1ewA7LJJ5j2jYKT/5bu60kyqU2/u99w2G2T//hCA5vXT9mQfKFD5/Fxp17KSuvYNyi4qhIk+4HNvCc0t+sbvWYbQN6HcSDF3Sleb0avrN/VpYDG9WMygjqhLl8ZC6gFb1GExC7km7TuHbU2IXJEQc24IgDG0Rtq129gL6d/E1zP6VTc07p1Nxxn1VZO1GjMJ/nLjuSzi3r0rJ+Tb6auSa8wpbJPZZU3P8dcBTHtm9Mo9rVaBiard25ZT06NKvLgF4HhRdF73toU6oV5IUjua5sXDtK0dujrAAa1ipkS2iVpe62+2GeB+DGvh04s2sLZhZtZf66Hbw0dqnr9Yk4p4oYfFYnPvttddQawbeddgjPfBu9otigkw+O6z5KZOZ2uya1fS9+ct2J7VixaVfUDNlUoV03Gk2Oct4RB9ChWV1qVy/g0mMO8gwPPbtby3AD9uxl3bn7rE50CuWKeuSibuGZ116RQO2b1g6H5ZqMua0339/Rh3+c05lh1/eKSflxYocmDLAM5h/ctA4XHdmaS44yZmsPsowBWdMDjL41km78wu6RaK4rj23DVzefSPN6kZ7Dn09uT9vQYPo9Z3fiq5tPDDdmJk1DPY1zD2/JpzccT8NahVx6zIH857IjXa/XiZqF3u7Aiy1Zbu86s1OlVjMLgrboNRpNFM3q1ogZZO/ZrhGX9jgwPKjtxPd39GF7SSkfTy1iwfodbNtTGp57cf1JzmtEvHu9Y+orOjavy6JHzqIwP89xsZlDmtflg4HHsn57CRd0b8W/+0cr5Icv7Maf3p5C07rVqVGYH05F0ufQZhzSvC4dmkWPQ3Q9oB4/LNjI6V2ac+RBDfnt/n4AjnNQzj28ZXht3qGXH8UbPy1jSigJ3ItXHM2W3fv420czovLjNKlTncd/140TOjThk1C2zmoFeTHr66YKreg1Gk1cCvPzePySwx33jbmtN7VCA9v1ahQyfNBx7Npb5romMRgDy/b0wE7nBPj+jpMdZyRbM9LaOb1Lc36991Sa1a0BwGmdm7N4w04ahHocNQrzefWqHuHkbfVC2+2LgFQryOOvp3TgtC7NWVa8i1s+mB61yEmL+jV457pe4TkcBzWuxUGNa9G8Xo0oRd+tVT1O7Wy44cbd2Zfdpcb17NprnO/ta3ty1eu/et6PyqAVvUajqRSHOET41K5eEI4scuKrm0+KmlntRfumEeu7ZmE+e3yuyGQqeYA7zziUPx7fhmb1ItusYyUdQueoUz12jOH2fkaUk7nmcIVSXNbzQN7/dRU7Skodo7ee+v0RHPvod/Rs24jf92gdFSRgzsmAyMpXzepV56yuLZi9xt+aw0HRil6j0aSdmtXyE5rVPfbvfdi62z07pBv5eRIOcbVuO71Lc76Zu56/9DmYNk1qey4Rmh+y5CsqFPefexiHNK9L745GaGu1gjxOtoS5tqhfw1fK4a6t6rNw/U4a165OrWoFjouzJwOt6DUaTZWhWd0aUZZ6ZXn+8iPZtqeUgvy8qBTeTpjzKcorFDWr5XONJTngwofPSuj8/3dRN647sR1N61anIE9i1pRNFlrRazSa/ZbqBfk0q+uvZ2HOii5M4sIrNQrzOewAI5dUQb6gXJf6qBzitfp6pujRo4eaMiX1C+ZqNBqNX8orFP8as4DrTmwXlc8pWxCRqUopx3zn2qLXaDQaH+TnCX8PLeFZ1dATpjQajSbH0Ypeo9Fochyt6DUajSbH0Ypeo9Fochyt6DUajSbH8aXoReRMEVkgIotFZLBLmT4iMl1E5ojIWMv25SIyK7RPx0xqNBpNmokbXiki+cBQ4HSgCJgsIl8opeZayjQA/gucqZRaKSL2hNt9lVLuqxFoNBqNJmX4seh7AouVUkuVUvuAD4ALbGUuBz5RSq0EUEqlPpO+RqPRaHzhZ8JUK2CV5XsRYE8ifQhQKCI/AnWBZ5VSb4f2KWCMiCjgJaXUy04nEZGBwMDQ150ikuiaYk2AbO49ZLt8oGVMBtkuH2S/jNkuH2SXjK4ry/hR9E7radnzJhQARwOnAjWBiSLyi1JqIXCCUmpNyJ3zjYjMV0qNsx1PqAFwbASCICJT3KYBZwPZLh9oGZNBtssH2S9jtssHVUNG8Oe6KQIOtHxvDaxxKDNKKbUr5IsfBxwBoJRaE/q/AfgUwxWk0Wg0mjThR9FPBjqKSDsRqQb0B76wlfkcOElECkSkFoZrZ56I1BaRugAiUhvoB3ivyKvRaDSapBLXdaOUKhORm4DRQD7wulJqjogMCu1/USk1T0RGATOBCuBVpdRsEWkPfBpaeqsAeE8pNSpVFxOi0u6fFJPt8oGWMRlku3yQ/TJmu3xQNWTMzjTFGo1Go0keemasRqPR5Dha0Ws0Gk2OkzOK3k+ahjTJcaCI/CAi80LpIG4JbW8kIt+IyKLQ/4aWY+4Oyb1ARM5Ik5z5IvKbiHyVpfI1EJGPRWR+6F4el00yishtod93toi8LyI1Mi2fiLwuIhtEZLZlW2CZROToUNqSxSLyHwkNsqVQxidDv/NMEfk0NNM+IzI6yWfZ9zcRUSLSJFPyJYxSqsr/YQwSLwHaA9WAGUCXDMnSEjgq9LkusBDoAjwBDA5tHww8HvrcJSRvdaBd6Dry0yDn7cB7wFeh79km31vA9aHP1YAG2SIjxiTCZUDN0PfhwNWZlg/oDRwFzLZsCywT8CtwHMYcmq+Bs1IsYz+gIPT58UzK6CRfaPuBGAEpK4AmmbyHifzlikXvJ01DWlBKrVVKTQt93gHMw1AMF2AoL0L/Lwx9vgD4QCm1Vym1DFhMiucaiEhr4BzgVcvmbJKvHsYL9xqAUmqfUmprNsmIEUVWU0QKgFoYc0syKp8yJiJutm0OJJOItATqKaUmKkNjvW05JiUyKqXGKKXKQl9/wZirkxEZXe4hwDPA34meLJqRe5gIuaLondI0tMqQLGFEpC1wJDAJaK6UWgtGYwCYid8yIfu/MR7aCsu2bJKvPbAReCPkXno1NA8jK2RUSq0GngJWAmuBbUqpMdkin42gMrUKfbZvTxfXYljAkCUyisj5wGql1AzbrqyQzw+5ouj9pGlIKyJSB/gfcKtSartXUYdtKZNdRM4FNiilpvo9xGFbqu9tAUb3+QWl1JHALgy3gxvpvocNMay5dsABQG0RucLrEIdtmY5rdpMpY7KKyL1AGTDM3OQiS9pkFGMC6L3A/U67XeTIut87VxS9nzQNaUNECjGU/DCl1CehzetDXTpC/80Mn+mW/QTgfBFZjuHiOkVE3s0i+cxzFimlJoW+f4yh+LNFxtOAZUqpjUqpUuAT4Pgsks9KUJmKiLhOrNtTioj8ETgXGBByd2SLjAdjNOgzQu9Ma2CaiLTIEvl8kSuK3k+ahrQQGl1/DZinlHrasusL4I+hz3/ESBthbu8vItVFpB3QEWMgJyUope5WSrVWSrXFuE/fK6WuyBb5QjKuA1aJyKGhTacCc7NIxpXAsSJSK/R7n4oxFpMt8lkJJFPIvbNDRI4NXdtVlmNSgoicCdwFnK+U2m2TPaMyKqVmKaWaKaXaht6ZIoxgi3XZIJ9vMjkSnMw/4GyMCJclwL0ZlONEjG7aTGB66O9soDHwHbAo9L+R5Zh7Q3IvII2j80AfIlE3WSUf0B2YErqPnwENs0lG4J/AfIzcTe9gRF5kVD7gfYwxg1IMhXRdIjIBPULXtQR4ntAM+hTKuBjD122+Ly9mSkYn+Wz7lxOKusnUPUzkT6dA0Gg0mhwnV1w3Go1Go3FBK3qNRqPJcbSi12g0mhxHK3qNRqPJcbSi12g0mhxHK3qNRqPJcbSi12g0mhzn/wH72jrWGW0RMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "003eac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 646us/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "485b1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error ,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fba7b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411517756959047"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec19ac60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83149.07260289858"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4b1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
